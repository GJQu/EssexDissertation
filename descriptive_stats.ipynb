{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive stats for Aggregate Health Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gavin Qu, March 28th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lf_stat</th>\n",
       "      <th>changejbstat</th>\n",
       "      <th>private</th>\n",
       "      <th>hrgpay</th>\n",
       "      <th>hrnpay</th>\n",
       "      <th>logpay</th>\n",
       "      <th>earnings</th>\n",
       "      <th>education</th>\n",
       "      <th>agghealth</th>\n",
       "      <th>pidp</th>\n",
       "      <th>wave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.923610</td>\n",
       "      <td>5.192707</td>\n",
       "      <td>1.934937</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22445</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.037906</td>\n",
       "      <td>7.500577</td>\n",
       "      <td>2.201428</td>\n",
       "      <td>1566.449951</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22445</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.323737</td>\n",
       "      <td>11.193169</td>\n",
       "      <td>2.661918</td>\n",
       "      <td>2482.590088</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22445</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.251269</td>\n",
       "      <td>10.385414</td>\n",
       "      <td>2.788171</td>\n",
       "      <td>2816.669922</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22445</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.732056</td>\n",
       "      <td>11.539349</td>\n",
       "      <td>2.817326</td>\n",
       "      <td>2900.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22445</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533471</th>\n",
       "      <td>533471</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.904050</td>\n",
       "      <td>18.372375</td>\n",
       "      <td>3.254399</td>\n",
       "      <td>4489.689941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1653277290</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533472</th>\n",
       "      <td>533472</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.040330</td>\n",
       "      <td>23.078698</td>\n",
       "      <td>3.179733</td>\n",
       "      <td>4166.669922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1653277290</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533473</th>\n",
       "      <td>533473</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.866778</td>\n",
       "      <td>19.615682</td>\n",
       "      <td>3.362691</td>\n",
       "      <td>5003.189941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1653277290</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533474</th>\n",
       "      <td>533474</td>\n",
       "      <td>1</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1653277290</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533475</th>\n",
       "      <td>533475</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.397703</td>\n",
       "      <td>18.304581</td>\n",
       "      <td>3.194489</td>\n",
       "      <td>4228.609863</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1653277290</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533476 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index lf_stat changejbstat  private     hrgpay     hrnpay    logpay  \\\n",
       "0            0       1           NA      0.0   6.923610   5.192707  1.934937   \n",
       "1            1       1            0      0.0   9.037906   7.500577  2.201428   \n",
       "2            2       1            0      0.0  14.323737  11.193169  2.661918   \n",
       "3            3       1            0      0.0  16.251269  10.385414  2.788171   \n",
       "4            4       1            0      0.0  16.732056  11.539349  2.817326   \n",
       "...        ...     ...          ...      ...        ...        ...       ...   \n",
       "533471  533471       1           NA      1.0  25.904050  18.372375  3.254399   \n",
       "533472  533472       1            0      1.0  24.040330  23.078698  3.179733   \n",
       "533473  533473       1            0      1.0  28.866778  19.615682  3.362691   \n",
       "533474  533474       1           NA      NaN        NaN        NaN       NaN   \n",
       "533475  533475       1            0      1.0  24.397703  18.304581  3.194489   \n",
       "\n",
       "           earnings  education  agghealth        pidp wave  \n",
       "0       1200.000000        2.0        2.0       22445    d  \n",
       "1       1566.449951        2.0        2.0       22445    e  \n",
       "2       2482.590088        2.0        2.0       22445    f  \n",
       "3       2816.669922        2.0        2.0       22445    g  \n",
       "4       2900.000000        2.0        2.0       22445    h  \n",
       "...             ...        ...        ...         ...  ...  \n",
       "533471  4489.689941        NaN        2.0  1653277290    f  \n",
       "533472  4166.669922        NaN        2.0  1653277290    g  \n",
       "533473  5003.189941        NaN        2.0  1653277290    h  \n",
       "533474          NaN        NaN        2.0  1653277290    i  \n",
       "533475  4228.609863        4.0        2.0  1653277290    k  \n",
       "\n",
       "[533476 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_stata('/Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/combined_panel_data.dta')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Stats\n",
    "1.\tPay density plot split by health status\n",
    "2.\tHours worked density plot split by health status\n",
    "3.\tLabour force status histogram split by health status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, prepare the health status change variable\n",
    "df['prev_agghealth'] = df.groupby('pidp')['agghealth'].shift(1)\n",
    "df['health_status_change'] = ((df['agghealth'] == 1) & (df['prev_agghealth'] == 2)).astype(int)\n",
    "\n",
    "# 1. Pay density plot split by health status\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.kdeplot(data=df, x='hrgpay', hue='health_status_change', common_norm=False)\n",
    "plt.title('Pay Density Plot Split by Health Status Change')\n",
    "\n",
    "# 2. Hours worked density plot split by health status\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.kdeplot(data=df, x='hrnpay', hue='health_status_change', common_norm=False)\n",
    "plt.title('Hours Worked Density Plot Split by Health Status Change')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Labour force status histogram split by health status\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.histplot(data=df, x='lf_stat', hue='health_status_change', multiple=\"dodge\", shrink=.8)\n",
    "plt.title('Labour Force Status Histogram Split by Health Status Change')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct new dataframe with hcond, hcondn, and jbhrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "# use latin-1 encoding if UTF8 does not work\n",
    "wave1, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/a_indresp.dta\")\n",
    "wave2, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/b_indresp.dta\")\n",
    "wave3, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/c_indresp.dta\", encoding=\"iso-8859-1\")\n",
    "wave4, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/d_indresp.dta\")\n",
    "wave5, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/e_indresp.dta\", encoding=\"iso-8859-1\")\n",
    "wave6, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/f_indresp.dta\")\n",
    "wave7, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/g_indresp.dta\")\n",
    "wave8, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/h_indresp.dta\")\n",
    "wave9, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/i_indresp.dta\")\n",
    "wave10, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/j_indresp.dta\")\n",
    "wave11, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/k_indresp.dta\")\n",
    "wave12, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/l_indresp.dta\")\n",
    "wave13, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/m_indresp.dta\")\n",
    "\n",
    "df1 = pd.DataFrame(wave1)\n",
    "df2 = pd.DataFrame(wave2)\n",
    "df3 = pd.DataFrame(wave3)\n",
    "df4 = pd.DataFrame(wave4)\n",
    "df5 = pd.DataFrame(wave5)\n",
    "df6 = pd.DataFrame(wave6)\n",
    "df7 = pd.DataFrame(wave7)\n",
    "df8 = pd.DataFrame(wave8)\n",
    "df9 = pd.DataFrame(wave9)\n",
    "df10 = pd.DataFrame(wave10)\n",
    "df11 = pd.DataFrame(wave11)\n",
    "df12 = pd.DataFrame(wave12)\n",
    "df13 = pd.DataFrame(wave13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter the variable of interest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  function to include the 'wave' assignment\n",
    "def select_and_rename(wave_df, wave_prefix, variables, wave_letter):\n",
    "    # Select variables that exist in the current wave's DataFrame\n",
    "    selected_vars = {f\"{wave_prefix}_{var}\": var for var in variables if f\"{wave_prefix}_{var}\" in wave_df.columns}\n",
    "\n",
    "    # Include 'pidp'\n",
    "    if 'pidp' in wave_df.columns:\n",
    "        selected_vars['pidp'] = 'pidp'\n",
    "\n",
    "    # Add the 'wave' column with the specified wave letter\n",
    "    wave_df['wave'] = wave_letter\n",
    "    selected_vars['wave'] = 'wave'\n",
    "\n",
    "    # Select and rename the existing columns\n",
    "    selected_columns = list(selected_vars.keys())\n",
    "    return wave_df[selected_columns].rename(columns=selected_vars)\n",
    "\n",
    "# List of all possible 'hcond' and 'hcondn' variables\n",
    "all_possible_vars = ['jbhrs', 'jbot'] + [f'hcond{i}' for i in range(1, 23)] + [f'hcondn{i}' for i in range(1, 23)]\n",
    "\n",
    "# Apply the function to each wave DataFrame\n",
    "df1_selected = select_and_rename(df1, 'a', all_possible_vars, 'a')\n",
    "df2_selected = select_and_rename(df2, 'b', all_possible_vars, 'b')\n",
    "df3_selected = select_and_rename(df3, 'c', all_possible_vars, 'c')\n",
    "df4_selected = select_and_rename(df4, 'd', all_possible_vars, 'd')\n",
    "df5_selected = select_and_rename(df5, 'e', all_possible_vars, 'e')\n",
    "df6_selected = select_and_rename(df6, 'f', all_possible_vars, 'f')\n",
    "df7_selected = select_and_rename(df7, 'g', all_possible_vars, 'g')\n",
    "df8_selected = select_and_rename(df8, 'h', all_possible_vars, 'h')\n",
    "df9_selected = select_and_rename(df9, 'i', all_possible_vars, 'i')\n",
    "df10_selected = select_and_rename(df10, 'j', all_possible_vars, 'j')\n",
    "df11_selected = select_and_rename(df11, 'k', all_possible_vars, 'k')\n",
    "df12_selected = select_and_rename(df12, 'l', all_possible_vars, 'l')\n",
    "df13_selected = select_and_rename(df13, 'm', all_possible_vars, 'm')\n",
    "\n",
    "# Now concatenate all the selected wave DataFrames into a single DataFrame\n",
    "all_waves_df = pd.concat(\n",
    "    [df1_selected, df2_selected, df3_selected, df4_selected, df5_selected, \n",
    "     df6_selected, df7_selected, df8_selected, df9_selected, df10_selected, \n",
    "     df11_selected, df12_selected, df13_selected], \n",
    "    ignore_index=True, \n",
    "    sort=False\n",
    ")\n",
    "# Proceed with merging all_waves_df with your main DataFrame\n",
    "df_combined_hcond = df.merge(all_waves_df, on=['pidp', 'wave'], how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
