{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the Frailty Index\n",
    "#### April 28th by Gavin Qu\n",
    "First we do the data cleaning by concatenating dataframes using pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use latin-1 encoding if UTF8 does not work\n",
    "wave1, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/a_indresp.dta\")\n",
    "wave2, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/b_indresp.dta\")\n",
    "wave3, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/c_indresp.dta\", encoding=\"iso-8859-1\")\n",
    "wave4, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/d_indresp.dta\")\n",
    "wave5, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/e_indresp.dta\", encoding=\"iso-8859-1\")\n",
    "wave6, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/f_indresp.dta\")\n",
    "wave7, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/g_indresp.dta\")\n",
    "wave8, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/h_indresp.dta\")\n",
    "wave9, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/i_indresp.dta\")\n",
    "wave10, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/j_indresp.dta\")\n",
    "wave11, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/k_indresp.dta\")\n",
    "wave12, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/l_indresp.dta\")\n",
    "wave13, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/m_indresp.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the death data in the xhhrel.dta, the variable for it is 'dcsedfl_dv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/xhhrel.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Columns to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of base columns (personal ID)\n",
    "base_columns = ['pidp']\n",
    "\n",
    "# Age columns for 13 waves stored as a list\n",
    "age_columns = [f'{chr(97+i)}_age_dv' for i in range(13)]  \n",
    "\n",
    "# \"Difficulty doing something\" columns for 13 waves, from 'disdif1' to 'disdif12'\n",
    "difficulty_columns = [f'{chr(97+i)}_disdif{j}' for i in range(13) for j in range(1, 13)]\n",
    "\n",
    "# Combine all columns to extract\n",
    "columns_to_extract = base_columns + age_columns + difficulty_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract data and include waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data and add wave information with corrected column name\n",
    "def extract_wave_data(wave, wave_letter):\n",
    "    # Include the correct personal ID column\n",
    "    specific_columns = [f'{wave_letter}_age_dv'] + [f'{wave_letter}_disdif{j}' for j in range(1, 13)]\n",
    "    specific_columns.insert(0, 'pidp')  # Insert 'pidp' as the first column\n",
    "    \n",
    "    # Create a new dataframe with the specified columns\n",
    "    df = wave[specific_columns]\n",
    "    df['wave'] = wave_letter  # Add a wave identifier\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of extracted dataframes for each wave\n",
    "waves_extracted = [\n",
    "    extract_wave_data(wave1, 'a'),\n",
    "    extract_wave_data(wave2, 'b'),\n",
    "    extract_wave_data(wave3, 'c'),\n",
    "    extract_wave_data(wave4, 'd'),\n",
    "    extract_wave_data(wave5, 'e'),\n",
    "    extract_wave_data(wave6, 'f'),\n",
    "    extract_wave_data(wave7, 'g'),\n",
    "    extract_wave_data(wave8, 'h'),\n",
    "    extract_wave_data(wave9, 'i'),\n",
    "    extract_wave_data(wave10, 'j'),\n",
    "    extract_wave_data(wave11, 'k'),\n",
    "    extract_wave_data(wave12, 'l'),\n",
    "    extract_wave_data(wave13, 'm'),\n",
    "]\n",
    "\n",
    "# Concatenate all extracted dataframes\n",
    "df_combined = pd.concat(waves_extracted, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count:\n",
      " pidp               0\n",
      "a_age_dv      482482\n",
      "a_disdif1     482482\n",
      "a_disdif2     482482\n",
      "a_disdif3     482482\n",
      "               ...  \n",
      "m_disdif8     505478\n",
      "m_disdif9     505478\n",
      "m_disdif10    505478\n",
      "m_disdif11    505478\n",
      "m_disdif12    505478\n",
      "Length: 171, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Total count of missing values in each column\n",
    "missing_values_count = df_combined.isna().sum()\n",
    "\n",
    "# Display the count of missing values\n",
    "print(\"Missing Values Count:\\n\", missing_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "                pidp      a_age_dv     a_disdif1     a_disdif2     a_disdif3  \\\n",
      "count  5.334760e+05  50994.000000  50994.000000  50994.000000  50994.000000   \n",
      "mean   7.791696e+08     45.638781     -5.166490     -5.142880     -5.235557   \n",
      "std    4.651655e+08     18.189291      3.909239      3.943244      3.807181   \n",
      "min    2.244500e+04     15.000000     -8.000000     -8.000000     -8.000000   \n",
      "25%    4.080871e+08     31.000000     -8.000000     -8.000000     -8.000000   \n",
      "50%    7.483971e+08     44.000000     -8.000000     -8.000000     -8.000000   \n",
      "75%    1.157270e+09     59.000000      0.000000      0.000000      0.000000   \n",
      "max    1.653277e+09    101.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "          a_disdif4     a_disdif5    a_disdif6     a_disdif7     a_disdif8  \\\n",
      "count  50994.000000  50994.000000  50994.00000  50994.000000  50994.000000   \n",
      "mean      -5.255638     -5.256187     -5.25954     -5.276307     -5.238303   \n",
      "std        3.776754      3.775917      3.77080      3.745065      3.803042   \n",
      "min       -8.000000     -8.000000     -8.00000     -8.000000     -8.000000   \n",
      "25%       -8.000000     -8.000000     -8.00000     -8.000000     -8.000000   \n",
      "50%       -8.000000     -8.000000     -8.00000     -8.000000     -8.000000   \n",
      "75%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.00000      1.000000      1.000000   \n",
      "\n",
      "       ...     m_disdif3     m_disdif4     m_disdif5     m_disdif6  \\\n",
      "count  ...  27998.000000  27998.000000  27998.000000  27998.000000   \n",
      "mean   ...      0.036967      0.033288      0.012465      0.014322   \n",
      "std    ...      0.264504      0.257957      0.216035      0.220179   \n",
      "min    ...     -2.000000     -2.000000     -2.000000     -2.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "          m_disdif7     m_disdif8     m_disdif9    m_disdif10    m_disdif11  \\\n",
      "count  27998.000000  27998.000000  27998.000000  27998.000000  27998.000000   \n",
      "mean      -0.001286      0.029716     -0.005358      0.034895      0.024537   \n",
      "std        0.181861      0.251387      0.170219      0.260844      0.241448   \n",
      "min       -2.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "         m_disdif12  \n",
      "count  27998.000000  \n",
      "mean       0.064683  \n",
      "std        0.307997  \n",
      "min       -2.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        0.000000  \n",
      "max        1.000000  \n",
      "\n",
      "[8 rows x 170 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 533476 entries, 0 to 533475\n",
      "Columns: 171 entries, pidp to m_disdif12\n",
      "dtypes: float64(169), int64(1), object(1)\n",
      "memory usage: 696.0+ MB\n",
      "DataFrame Information:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics for numerical columns\n",
    "summary_statistics = df_combined.describe()\n",
    "\n",
    "# Display the summary\n",
    "print(\"Summary Statistics:\\n\", summary_statistics)\n",
    "\n",
    "# General information about the dataframe\n",
    "df_info = df_combined.info()\n",
    "\n",
    "# Display general information (includes data types and non-null counts)\n",
    "print(\"DataFrame Information:\\n\", df_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the data frame for deceased info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   osm_hh       pidp  sex  doby_dv  osm_hh_size  osm_hh_head  hhorig  sampst  \\\n",
      "0     687        687    2      -20            1            1       3       1   \n",
      "1    1367       1367    1      -20            2            1       3       1   \n",
      "2    1367       2051    1      -20            2            0       3       1   \n",
      "3    2727       2727    2      -20            4            1       3       1   \n",
      "4    2727  752052125    2     1966            4            0       3       1   \n",
      "\n",
      "   dcsedfl_dv  dcsedw_dv  ...  apx_rr_ef  spx_rr_ef  fpx_rr_ef  lpx_rr_ef  \\\n",
      "0           3         -8  ...         -8         -8         -8         -8   \n",
      "1           3         -8  ...         -8         -8         -8         -8   \n",
      "2           3         -8  ...         -8         -8         -8         -8   \n",
      "3           3         -8  ...         -8         -8         -8         -8   \n",
      "4           3         -8  ...         -8         -8         -8         -8   \n",
      "\n",
      "   gpx_rr_ef  bsbx_rr_ef  hsbx_rr_ef  lsbx_rr_ef  aux_rr_ef  mr_ef  \n",
      "0         -8          -8          -8          -8         -8      0  \n",
      "1         -8          -8          -8          -8         -8      0  \n",
      "2         -8          -8          -8          -8         -8      0  \n",
      "3         -8          -8          -8          -8         -8      0  \n",
      "4         -8          -8          -8          -8         -8      0  \n",
      "\n",
      "[5 rows x 406 columns]\n"
     ]
    }
   ],
   "source": [
    "print(death_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the death data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pidp  a_age_dv  a_disdif1  a_disdif2  a_disdif3  a_disdif4  a_disdif5  \\\n",
      "0  68001367      39.0       -8.0       -8.0       -8.0       -8.0       -8.0   \n",
      "1  68004087      59.0       -8.0       -8.0       -8.0       -8.0       -8.0   \n",
      "2  68006127      39.0        0.0        0.0        0.0        1.0        0.0   \n",
      "3  68006135      17.0       -8.0       -8.0       -8.0       -8.0       -8.0   \n",
      "4  68006807      72.0        1.0        1.0        0.0        0.0        1.0   \n",
      "\n",
      "   a_disdif6  a_disdif7  a_disdif8  ...  m_disdif4  m_disdif5  m_disdif6  \\\n",
      "0       -8.0       -8.0       -8.0  ...        NaN        NaN        NaN   \n",
      "1       -8.0       -8.0       -8.0  ...        NaN        NaN        NaN   \n",
      "2        0.0        0.0        0.0  ...        NaN        NaN        NaN   \n",
      "3       -8.0       -8.0       -8.0  ...        NaN        NaN        NaN   \n",
      "4        0.0        0.0        0.0  ...        NaN        NaN        NaN   \n",
      "\n",
      "   m_disdif7 m_disdif8  m_disdif9  m_disdif10  m_disdif11  m_disdif12  \\\n",
      "0        NaN       NaN        NaN         NaN         NaN         NaN   \n",
      "1        NaN       NaN        NaN         NaN         NaN         NaN   \n",
      "2        NaN       NaN        NaN         NaN         NaN         NaN   \n",
      "3        NaN       NaN        NaN         NaN         NaN         NaN   \n",
      "4        NaN       NaN        NaN         NaN         NaN         NaN   \n",
      "\n",
      "   dcsedfl_dv  \n",
      "0         3.0  \n",
      "1         3.0  \n",
      "2         3.0  \n",
      "3         3.0  \n",
      "4         1.0  \n",
      "\n",
      "[5 rows x 172 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge the combined dataframe with death_df based on 'pidp'\n",
    "df_with_death = pd.merge(df_combined, death_df[['pidp', 'dcsedfl_dv']], on='pidp', how='left')\n",
    "\n",
    "# Preview the first few rows after the merge\n",
    "print(df_with_death.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the death status count\n",
    "note that value of 1 is count as death in UKHLS, and 3 counts as alive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Death Status Count:\n",
      " dcsedfl_dv\n",
      "3.0    510908\n",
      "1.0     22466\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 533476 entries, 0 to 533475\n",
      "Columns: 172 entries, pidp to dcsedfl_dv\n",
      "dtypes: float64(170), int64(1), object(1)\n",
      "memory usage: 700.1+ MB\n",
      "DataFrame Summary:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Count the number of occurrences for each death status value\n",
    "death_status_count = df_with_death['dcsedfl_dv'].value_counts()\n",
    "\n",
    "# Display the count of death statuses\n",
    "print(\"Death Status Count:\\n\", death_status_count)\n",
    "\n",
    "# Display a summary of the dataframe to ensure the merge worked as expected\n",
    "df_summary = df_with_death.info()\n",
    "print(\"DataFrame Summary:\\n\", df_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and one-hot encoding for disdif\n",
    "We'll first create a function to convert values into binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert values to binary based on the given rules\n",
    "def convert_to_binary(value):\n",
    "    if value <= 0:  # Any value less than or equal to zero becomes 0\n",
    "        return 0\n",
    "    elif value == 1:  # The value of 1 remains 1\n",
    "        return 1\n",
    "    else:\n",
    "        return 0  # For safety, ensure other values convert to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function to disdif variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all \"disdif\" columns across 13 waves\n",
    "disdif_columns = [f'{chr(97+i)}_disdif{j}' for i in range(13) for j in range(1, 13)]\n",
    "\n",
    "# Apply the function to each \"disdif\" column\n",
    "for column in disdif_columns:\n",
    "    df_with_death[column] = df_with_death[column].apply(convert_to_binary)  # Apply the binary conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for unique values after the cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in sample 'disdif' column:\n",
      " [0 1]\n",
      "Disdif value counts:\n",
      " a_disdif1\n",
      "0    527289\n",
      "1      6187\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the unique values in a sample \"disdif\" column\n",
    "sample_disdif_unique_values = df_with_death[disdif_columns[0]].unique()\n",
    "\n",
    "# Display the unique values to ensure the conversion worked\n",
    "print(\"Unique values in sample 'disdif' column:\\n\", sample_disdif_unique_values)\n",
    "\n",
    "# Get a count of 0s and 1s to confirm the distribution\n",
    "disdif_value_counts = df_with_death[disdif_columns[0]].value_counts()  # Example for the first \"disdif\" column\n",
    "\n",
    "print(\"Disdif value counts:\\n\", disdif_value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frailty Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for individuals aged 52-53 at their starting point\n",
    "initial_age_df = df_with_death[(df_with_death['a_age_dv'] >= 52) & (df_with_death['a_age_dv'] <= 53)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the \"Disdif\" Variables and Death Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of \"disdif\" variables for each wave\n",
    "disdif_columns = [f'{chr(97 + i)}_disdif{j}' for i in range(13) for j in range(1, 13)]\n",
    "\n",
    "# Death variable indicating whether a person has died\n",
    "death_variable = 'dcsedfl_dv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Calculate the Frailty Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of possible health deficits for each wave\n",
    "total_disdifs = 12  # Total number of \"disdif\" variables\n",
    "\n",
    "# Function to calculate frailty index, with consideration for death\n",
    "def calculate_frailty_index(row, wave_letter, total_disdifs, death_var):\n",
    "    # List of \"disdif\" variables for the given wave\n",
    "    disdif_wave_columns = [f'{wave_letter}_disdif{j}' for j in range(1, 13)]\n",
    "\n",
    "    # Count the health deficits in the given row\n",
    "    health_deficits = row[disdif_wave_columns].sum()  # Number of ones in \"disdif\" columns\n",
    "\n",
    "    # Check if the person is deceased\n",
    "    has_died = row[death_var] == 1\n",
    "\n",
    "    # If the person has died, assign frailty index of 1\n",
    "    if has_died:\n",
    "        return 1\n",
    "    \n",
    "    # Calculate the frailty index as the ratio of health deficits to total possible deficits\n",
    "    return health_deficits / total_disdifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_86653/4163434907.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  initial_age_df[column_name] = initial_age_df.apply(\n"
     ]
    }
   ],
   "source": [
    "# Loop through each wave to calculate and add the frailty index\n",
    "for i in range(13):\n",
    "    wave_letter = chr(97 + i)  # Corresponding wave letter: 'a', 'b', 'c', ...\n",
    "    column_name = f'{wave_letter}_frailty'  # Name for the frailty index column\n",
    "    \n",
    "    # Apply the calculation to each row in the dataframe\n",
    "    initial_age_df[column_name] = initial_age_df.apply(\n",
    "        lambda row: calculate_frailty_index(row, wave_letter, total_disdifs, death_variable),\n",
    "        axis=1  # Apply row-wise\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and confirm the added columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics for Frailty Index:\n",
      "          a_frailty    b_frailty    c_frailty    d_frailty    e_frailty  \\\n",
      "count  1585.000000  1585.000000  1585.000000  1585.000000  1585.000000   \n",
      "mean      0.094374     0.038486     0.038486     0.038486     0.038486   \n",
      "std       0.221017     0.192427     0.192427     0.192427     0.192427   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.083333     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "         f_frailty    g_frailty    h_frailty    i_frailty    j_frailty  \\\n",
      "count  1585.000000  1585.000000  1585.000000  1585.000000  1585.000000   \n",
      "mean      0.038486     0.038486     0.038486     0.038486     0.038486   \n",
      "std       0.192427     0.192427     0.192427     0.192427     0.192427   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
      "\n",
      "         k_frailty    l_frailty    m_frailty  \n",
      "count  1585.000000  1585.000000  1585.000000  \n",
      "mean      0.038486     0.038486     0.038486  \n",
      "std       0.192427     0.192427     0.192427  \n",
      "min       0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.000000     0.000000  \n",
      "50%       0.000000     0.000000     0.000000  \n",
      "75%       0.000000     0.000000     0.000000  \n",
      "max       1.000000     1.000000     1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Compute summary statistics for all frailty index columns\n",
    "frailty_summary = initial_age_df[frailty_columns].describe()\n",
    "\n",
    "print(\"Summary Statistics for Frailty Index:\\n\", frailty_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
