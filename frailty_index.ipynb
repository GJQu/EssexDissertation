{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of the Frailty Index\n",
    "#### April 28th by Gavin Qu\n",
    "First we do the data cleaning by concatenating dataframes using pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use latin-1 encoding if UTF8 does not work\n",
    "wave1, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/a_indresp.dta\")\n",
    "wave2, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/b_indresp.dta\")\n",
    "wave3, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/c_indresp.dta\", encoding=\"iso-8859-1\")\n",
    "wave4, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/d_indresp.dta\")\n",
    "wave5, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/e_indresp.dta\", encoding=\"iso-8859-1\")\n",
    "wave6, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/f_indresp.dta\")\n",
    "wave7, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/g_indresp.dta\")\n",
    "wave8, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/h_indresp.dta\")\n",
    "wave9, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/i_indresp.dta\")\n",
    "wave10, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/j_indresp.dta\")\n",
    "wave11, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/k_indresp.dta\")\n",
    "wave12, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/l_indresp.dta\")\n",
    "wave13, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/m_indresp.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the death data in the xhhrel.dta, the variable for it is 'dcsedfl_dv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_df, meta = pyreadstat.read_dta(\"/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/xhhrel.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Columns to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of base columns (personal ID)\n",
    "base_columns = ['pidp']\n",
    "\n",
    "# Age columns for 13 waves stored as a list\n",
    "age_columns = [f'{chr(97+i)}_age_dv' for i in range(13)]  \n",
    "\n",
    "# \"Difficulty doing something\" columns for 13 waves, from 'disdif1' to 'disdif12'\n",
    "difficulty_columns = [f'{chr(97+i)}_disdif{j}' for i in range(13) for j in range(1, 13)]\n",
    "\n",
    "# Combine all columns to extract\n",
    "columns_to_extract = base_columns + age_columns + difficulty_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract data and include waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data and add wave information with corrected column name\n",
    "def extract_wave_data(wave, wave_letter):\n",
    "    # Include the correct personal ID column\n",
    "    specific_columns = [f'{wave_letter}_age_dv'] + [f'{wave_letter}_disdif{j}' for j in range(1, 13)]\n",
    "    specific_columns.insert(0, 'pidp')  # Insert 'pidp' as the first column\n",
    "    \n",
    "    # Create a new dataframe with the specified columns\n",
    "    df = wave[specific_columns]\n",
    "    df['wave'] = wave_letter  # Add a wave identifier\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of extracted dataframes for each wave\n",
    "waves_extracted = [\n",
    "    extract_wave_data(wave1, 'a'),\n",
    "    extract_wave_data(wave2, 'b'),\n",
    "    extract_wave_data(wave3, 'c'),\n",
    "    extract_wave_data(wave4, 'd'),\n",
    "    extract_wave_data(wave5, 'e'),\n",
    "    extract_wave_data(wave6, 'f'),\n",
    "    extract_wave_data(wave7, 'g'),\n",
    "    extract_wave_data(wave8, 'h'),\n",
    "    extract_wave_data(wave9, 'i'),\n",
    "    extract_wave_data(wave10, 'j'),\n",
    "    extract_wave_data(wave11, 'k'),\n",
    "    extract_wave_data(wave12, 'l'),\n",
    "    extract_wave_data(wave13, 'm'),\n",
    "]\n",
    "\n",
    "# Concatenate all extracted dataframes\n",
    "df_combined = pd.concat(waves_extracted, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Count:\n",
      " pidp               0\n",
      "a_age_dv      482482\n",
      "a_disdif1     482482\n",
      "a_disdif2     482482\n",
      "a_disdif3     482482\n",
      "               ...  \n",
      "m_disdif8     505478\n",
      "m_disdif9     505478\n",
      "m_disdif10    505478\n",
      "m_disdif11    505478\n",
      "m_disdif12    505478\n",
      "Length: 171, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Total count of missing values in each column\n",
    "missing_values_count = df_combined.isna().sum()\n",
    "\n",
    "# Display the count of missing values\n",
    "print(\"Missing Values Count:\\n\", missing_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "                pidp      a_age_dv     a_disdif1     a_disdif2     a_disdif3  \\\n",
      "count  5.334760e+05  50994.000000  50994.000000  50994.000000  50994.000000   \n",
      "mean   7.791696e+08     45.638781     -5.166490     -5.142880     -5.235557   \n",
      "std    4.651655e+08     18.189291      3.909239      3.943244      3.807181   \n",
      "min    2.244500e+04     15.000000     -8.000000     -8.000000     -8.000000   \n",
      "25%    4.080871e+08     31.000000     -8.000000     -8.000000     -8.000000   \n",
      "50%    7.483971e+08     44.000000     -8.000000     -8.000000     -8.000000   \n",
      "75%    1.157270e+09     59.000000      0.000000      0.000000      0.000000   \n",
      "max    1.653277e+09    101.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "          a_disdif4     a_disdif5    a_disdif6     a_disdif7     a_disdif8  \\\n",
      "count  50994.000000  50994.000000  50994.00000  50994.000000  50994.000000   \n",
      "mean      -5.255638     -5.256187     -5.25954     -5.276307     -5.238303   \n",
      "std        3.776754      3.775917      3.77080      3.745065      3.803042   \n",
      "min       -8.000000     -8.000000     -8.00000     -8.000000     -8.000000   \n",
      "25%       -8.000000     -8.000000     -8.00000     -8.000000     -8.000000   \n",
      "50%       -8.000000     -8.000000     -8.00000     -8.000000     -8.000000   \n",
      "75%        0.000000      0.000000      0.00000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.00000      1.000000      1.000000   \n",
      "\n",
      "       ...     m_disdif3     m_disdif4     m_disdif5     m_disdif6  \\\n",
      "count  ...  27998.000000  27998.000000  27998.000000  27998.000000   \n",
      "mean   ...      0.036967      0.033288      0.012465      0.014322   \n",
      "std    ...      0.264504      0.257957      0.216035      0.220179   \n",
      "min    ...     -2.000000     -2.000000     -2.000000     -2.000000   \n",
      "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
      "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "          m_disdif7     m_disdif8     m_disdif9    m_disdif10    m_disdif11  \\\n",
      "count  27998.000000  27998.000000  27998.000000  27998.000000  27998.000000   \n",
      "mean      -0.001286      0.029716     -0.005358      0.034895      0.024537   \n",
      "std        0.181861      0.251387      0.170219      0.260844      0.241448   \n",
      "min       -2.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "         m_disdif12  \n",
      "count  27998.000000  \n",
      "mean       0.064683  \n",
      "std        0.307997  \n",
      "min       -2.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        0.000000  \n",
      "max        1.000000  \n",
      "\n",
      "[8 rows x 170 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 533476 entries, 0 to 533475\n",
      "Columns: 171 entries, pidp to m_disdif12\n",
      "dtypes: float64(169), int64(1), object(1)\n",
      "memory usage: 696.0+ MB\n",
      "DataFrame Information:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics for numerical columns\n",
    "summary_statistics = df_combined.describe()\n",
    "\n",
    "# Display the summary\n",
    "print(\"Summary Statistics:\\n\", summary_statistics)\n",
    "\n",
    "# General information about the dataframe\n",
    "df_info = df_combined.info()\n",
    "\n",
    "# Display general information (includes data types and non-null counts)\n",
    "print(\"DataFrame Information:\\n\", df_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
