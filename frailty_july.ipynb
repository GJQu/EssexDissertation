{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Successful Attempt of Frailty Index\n",
    "#### By Gavin Qu, July 7th 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction\n",
    "- Reads each wave's data from its respective file\n",
    "- Extracts only the specified variables for each wave\n",
    "- Adds a 'wave' column to identify the source wave for each row\n",
    "- Combines all waves' data into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed wave a, extracted 29 variables\n",
      "Processed wave b, extracted 29 variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_96863/1201396102.py:33: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  available_columns = stata_file.variable_labels().keys()\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_96863/1201396102.py:39: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df_wave = pd.read_stata(file_path, columns=wave_vars, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed wave c, extracted 45 variables\n",
      "Processed wave d, extracted 45 variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_96863/1201396102.py:33: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  available_columns = stata_file.variable_labels().keys()\n",
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_96863/1201396102.py:39: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df_wave = pd.read_stata(file_path, columns=wave_vars, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed wave e, extracted 45 variables\n",
      "Processed wave f, extracted 45 variables\n",
      "Processed wave g, extracted 45 variables\n",
      "Processed wave h, extracted 45 variables\n",
      "Processed wave i, extracted 45 variables\n",
      "Processed wave j, extracted 43 variables\n",
      "Processed wave k, extracted 43 variables\n",
      "Processed wave l, extracted 43 variables\n",
      "Processed wave m, extracted 43 variables\n",
      "Extracted data saved to /Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/Data/ukhls_extracted.csv\n",
      "Total rows: 533476\n",
      "Total columns: 534\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set directory\n",
    "data_dir = '/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls'\n",
    "output_dir = '/Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/Data'\n",
    "\n",
    "# Base list of relevant variables (without wave prefix)\n",
    "base_variables = [\n",
    "    'pidp',\n",
    "    'age_dv',\n",
    "    'disdif1', 'disdif2', 'disdif3', 'disdif4', 'disdif5', 'disdif6', 'disdif7', 'disdif8',\n",
    "    'disdif9', 'disdif10', 'disdif11',\n",
    "    'hcond1', 'hcond2', 'hcond3', 'hcond4', 'hcond5', 'hcond6', 'hcond7', 'hcond8', \n",
    "    'hcond9', 'hcond10', 'hcond11', 'hcond12', 'hcond13', 'hcond14', 'hcond15', 'hcond16', \n",
    "    'hcondn1', 'hcondn2', 'hcondn3', 'hcondn4', 'hcondn5', 'hcondn6', 'hcondn7', 'hcondn8', \n",
    "    'hcondn9', 'hcondn10', 'hcondn11', 'hcondn12', 'hcondn13', 'hcondn14', 'hcondn15', 'hcondn16', \n",
    "    'hcondever1', 'hcondever2', 'hcondever3', 'hcondever4', 'hcondever5', 'hcondever6', 'hcondever7', 'hcondever8', \n",
    "    'hcondever9', 'hcondever10', 'hcondever11', 'hcondever12', 'hcondever13', 'hcondever14', 'hcondever15', 'hcondever16', \n",
    "    'hcondnew1', 'hcondnew2', 'hcondnew3', 'hcondnew4', 'hcondnew5', 'hcondnew6', 'hcondnew7', 'hcondnew8', \n",
    "    'hcondnew9', 'hcondnew10', 'hcondnew11', 'hcondnew12', 'hcondnew13', 'hcondnew14', 'hcondnew15', 'hcondnew16', \n",
    "]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Process each wave\n",
    "for wave in 'abcdefghijklm':\n",
    "    file_path = os.path.join(data_dir, f'{wave}_indresp.dta')\n",
    "    \n",
    "    # Read the .dta file to get available columns\n",
    "    with pd.read_stata(file_path, iterator=True) as stata_file:\n",
    "        available_columns = stata_file.variable_labels().keys()\n",
    "    \n",
    "    # Create a list of variables that exist in this wave's data\n",
    "    wave_vars = ['pidp'] + [f'{wave}_{var}' for var in base_variables[1:] if f'{wave}_{var}' in available_columns]\n",
    "    \n",
    "    # Read only the available columns\n",
    "    df_wave = pd.read_stata(file_path, columns=wave_vars, convert_categoricals=False)\n",
    "    df_wave['wave'] = wave\n",
    "    \n",
    "    df_list.append(df_wave)\n",
    "    print(f\"Processed wave {wave}, extracted {len(wave_vars)} variables\")\n",
    "\n",
    "# Combine all DataFrames\n",
    "df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = os.path.join(output_dir, 'ukhls_extracted.csv')\n",
    "df_combined.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Extracted data saved to {output_path}\")\n",
    "print(f\"Total rows: {len(df_combined)}\")\n",
    "print(f\"Total columns: {len(df_combined.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling and New Variable Construction\n",
    "#### Creating the 'healthcond' variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the next script using the 'ukhls_extracted.csv' we just created, I want to create new variables '{prefix}_healthcond1' to '{prefix}_healthcond16' for all 13 waves. \n",
    "I'm doing this as a way to track chronic illnesses overtime, since 'hcond', 'hcondn', 'hcondever', 'hcondnew' are all tracked differently. For example, 'hcond' tracks chronic illness status of those new participants in the dataset, so wave a of 'hcond' tracks all new participants, while wave c only tracks the newly entered participants. Where 'hcondn' and 'hcondnew' only tracks the existing participants from certain waves. and some of those waves of hcondn and hcondnew don't exist because both of them together forms the complete picture. \n",
    "And 'hcondever' tracks all participants again at wave 10 only, so it's asking all existing participants up to wave 10 whether they are diagnosed with any of the 16 chronic illnesses, an answer of 0 is no, 1 is yes, negative 1 to negative 9 are various forms of missing data. \n",
    "'hcond' and 'hcondever' ask individuals if they have ever been diagnosed with a specific illness, while 'hcondn' and 'hcondnew' ask if any new illness have been diagnosed. So hcond from wave 2 and on will have lots of negative values since it only tracks new participants answer as 1 and 0. While 'hcondn' and 'hcondnew' and 'hcondever' will ask all existing ones if a new condition as been diagnosed. \n",
    "\n",
    "The new variables I want to create is called {prefix}_healthcond_1 to 16, that basically tracks a positive diagnoses as 1, and tracks a negative diagnoses as 0, but since we're talking about chronic illness, once an pidp answers a 1 in any wave, any wave forward will carry that 1. While a 0 value should only be there if current and all previous wave of that health condition variable is 0. And it should be NaN if all previous and current wave is negative number.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('/Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/Data/ukhls_extracted.csv')\n",
    "\n",
    "# Define waves and health condition variables\n",
    "waves = 'abcdefghijklm'\n",
    "health_vars = ['hcond', 'hcondn', 'hcondever', 'hcondnew']\n",
    "\n",
    "# Create a list of all possible health condition columns\n",
    "all_health_cols = [f'{w}_{v}{i}' for w in waves for v in health_vars for i in range(1, 17)]\n",
    "\n",
    "# Filter to only include columns that exist in the dataframe\n",
    "health_cols = [col for col in all_health_cols if col in df.columns]\n",
    "\n",
    "# Create a mask for positive diagnoses (1), negative diagnoses (0), and missing data\n",
    "positive_mask = df[health_cols] == 1\n",
    "negative_mask = (df[health_cols] == 0) | (df[health_cols] < 0)\n",
    "missing_mask = df[health_cols].isna()\n",
    "\n",
    "# Create new health condition variables\n",
    "for i in range(1, 17):\n",
    "    cols_i = [col for col in health_cols if col.endswith(str(i))]\n",
    "    df[f'healthcond_{i}'] = np.select(\n",
    "        [positive_mask[cols_i].any(axis=1),\n",
    "         negative_mask[cols_i].all(axis=1) & ~missing_mask[cols_i].all(axis=1)],\n",
    "        [1, 0],\n",
    "        default=np.nan\n",
    "    )\n",
    "\n",
    "# Forward fill the 1s for each pidp\n",
    "df = df.sort_values(['pidp', 'wave'])\n",
    "for i in range(1, 17):\n",
    "    df[f'healthcond_{i}'] = df.groupby('pidp')[f'healthcond_{i}'].transform(\n",
    "        lambda x: x.replace({0: np.nan}).ffill().fillna(0))\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv('ukhls_health_conditions_vectorized.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
