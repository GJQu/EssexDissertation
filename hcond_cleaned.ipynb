{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Condition using 'hcond' and 'hcondnew'\n",
    "### By Gavin Qu - May 23rd 2024\n",
    "#### Data Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tEncode hcond and new healthcond variables correctly \n",
    "-\tNote that individuals are asked about pre-existing health conditions on their first interview in the UKHLS – the hcond (i) variable, where i codes different conditions – and then asked whether they have developed new conditions in subsequent interviews – the hcondn(i) variable in waves 1-9 and hcondnew(i) in waves 10 onwards.\n",
    "-\thcond in wave 1 and new entrants for succeeding waves, hcondn in wave 1-9, hcondnew in wave 10-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, hcond1-19 has 1, 3-13 waves, and it's for new interviewees only. While hcondn1-19 have 2-9 waves asking the existing interviewees about newly devloped conditions, and hcondnew1-19 have wave 9-13 for the same questions. \n",
    "hcond21 and hcondnew21 only exist from wave 10-13, while hcondnew22 only exist from 10-13. \n",
    "\n",
    "'dcsedfl_dv' is death data, but it's onyl 50% accurate when it comes to health mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether the long panel dataset you created has all the correct values, including the special codes like missing values, proxy, refusal, etc., you can use pandas to display the unique values for each variable. This way, you can verify that all expected values are present in the dataset.\n",
    "**Here's a script that:**\n",
    "- Loads the long panel dataset.\n",
    "- Displays the unique values for each variable.\n",
    "- Checks for the presence of the specified special codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'pidp': [  68001367   68004087   68006127 ... 1644552890 1644675410 1649095330]\n",
      "Unique values in column 'wave': ['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm']\n",
      "Unique values in column 'variable': ['a_hcond11' 'a_hcond13' 'a_hcond5' 'a_hcond7' 'a_hcond1' 'a_hcond15'\n",
      " 'a_hcond17' 'a_hcond9' 'a_hcond10' 'a_hcond14' 'a_hcond16' 'a_hcond12'\n",
      " 'a_hcond8' 'a_hcond3' 'a_hcond6' 'a_hcond2' 'a_hcond4' 'b_hcondn9'\n",
      " 'b_hcondn1' 'b_hcondn6' 'b_hcondn11' 'b_hcondn10' 'b_hcondn8' 'b_hcondn4'\n",
      " 'b_hcondn7' 'b_hcondn17' 'b_hcondn14' 'b_hcondn2' 'b_hcondn3' 'b_hcondn5'\n",
      " 'b_hcondn15' 'b_hcondn16' 'b_hcondn13' 'b_hcondn12' 'c_hcondn17'\n",
      " 'c_hcondn10' 'c_hcondn1' 'c_hcond11' 'c_hcond14' 'c_hcond3' 'c_hcondn13'\n",
      " 'c_hcondn15' 'c_hcond17' 'c_hcondn4' 'c_hcond1' 'c_hcond7' 'c_hcondn3'\n",
      " 'c_hcondn11' 'c_hcondn14' 'c_hcondn5' 'c_hcond5' 'c_hcond4' 'c_hcond9'\n",
      " 'c_hcondn12' 'c_hcondn2' 'c_hcond16' 'c_hcondn16' 'c_hcond6' 'c_hcond13'\n",
      " 'c_hcond15' 'c_hcond8' 'c_hcond2' 'c_hcondn9' 'c_hcond12' 'c_hcondn7'\n",
      " 'c_hcondn8' 'c_hcond10' 'c_hcondn6' 'd_hcondn8' 'd_hcondn10' 'd_hcond6'\n",
      " 'd_hcondn7' 'd_hcondn5' 'd_hcondn4' 'd_hcond13' 'd_hcond7' 'd_hcond3'\n",
      " 'd_hcond2' 'd_hcond15' 'd_hcond5' 'd_hcondn16' 'd_hcond14' 'd_hcondn17'\n",
      " 'd_hcondn3' 'd_hcond17' 'd_hcondn9' 'd_hcond1' 'd_hcondn15' 'd_hcondn12'\n",
      " 'd_hcondn2' 'd_hcond11' 'd_hcondn6' 'd_hcondn14' 'd_hcond8' 'd_hcond9'\n",
      " 'd_hcond12' 'd_hcondn13' 'd_hcondn11' 'd_hcond16' 'd_hcond4' 'd_hcond10'\n",
      " 'd_hcondn1' 'e_hcond9' 'e_hcondn8' 'e_hcondn4' 'e_hcondn6' 'e_hcondn1'\n",
      " 'e_hcondn2' 'e_hcondn3' 'e_hcondn14' 'e_hcond2' 'e_hcond8' 'e_hcond15'\n",
      " 'e_hcondn13' 'e_hcond7' 'e_hcond16' 'e_hcond13' 'e_hcond17' 'e_hcondn5'\n",
      " 'e_hcondn7' 'e_hcond11' 'e_hcondn11' 'e_hcond10' 'e_hcondn17' 'e_hcond12'\n",
      " 'e_hcond3' 'e_hcondn10' 'e_hcond4' 'e_hcondn15' 'e_hcond1' 'e_hcondn16'\n",
      " 'e_hcond14' 'e_hcond5' 'e_hcond6' 'e_hcondn12' 'e_hcondn9' 'f_hcond2'\n",
      " 'f_hcond11' 'f_hcondn12' 'f_hcond4' 'f_hcondn14' 'f_hcond3' 'f_hcond5'\n",
      " 'f_hcondn5' 'f_hcondn9' 'f_hcondn16' 'f_hcond10' 'f_hcondn2' 'f_hcondn10'\n",
      " 'f_hcond13' 'f_hcondn17' 'f_hcond1' 'f_hcondn7' 'f_hcond16' 'f_hcondn15'\n",
      " 'f_hcondn6' 'f_hcond8' 'f_hcondn18' 'f_hcond18' 'f_hcondn1' 'f_hcondn11'\n",
      " 'f_hcondn13' 'f_hcond6' 'f_hcondn3' 'f_hcond9' 'f_hcond17' 'f_hcondn4'\n",
      " 'f_hcondn8' 'f_hcond14' 'f_hcond7' 'f_hcond12' 'f_hcond15' 'g_hcond2'\n",
      " 'g_hcond19' 'g_hcondn3' 'g_hcond17' 'g_hcondn1' 'g_hcond4' 'g_hcondn13'\n",
      " 'g_hcond18' 'g_hcondn17' 'g_hcond14' 'g_hcond7' 'g_hcondn5' 'g_hcondn11'\n",
      " 'g_hcond11' 'g_hcond12' 'g_hcondn6' 'g_hcondn19' 'g_hcond1' 'g_hcond6'\n",
      " 'g_hcond5' 'g_hcond10' 'g_hcond13' 'g_hcondn8' 'g_hcond3' 'g_hcondn15'\n",
      " 'g_hcondn9' 'g_hcondn10' 'g_hcondn4' 'g_hcondn18' 'g_hcondn12'\n",
      " 'g_hcondn14' 'g_hcond8' 'g_hcond9' 'g_hcondn7' 'g_hcondn2' 'g_hcond15'\n",
      " 'g_hcond16' 'g_hcondn16' 'h_hcond10' 'h_hcondn8' 'h_hcondn12'\n",
      " 'h_hcondn19' 'h_hcond3' 'h_hcond7' 'h_hcond2' 'h_hcondn17' 'h_hcond8'\n",
      " 'h_hcondn9' 'h_hcond12' 'h_hcondn5' 'h_hcondn16' 'h_hcondn4' 'h_hcond18'\n",
      " 'h_hcondn7' 'h_hcondn10' 'h_hcond16' 'h_hcond4' 'h_hcond9' 'h_hcond11'\n",
      " 'h_hcondn14' 'h_hcondn3' 'h_hcond14' 'h_hcondn13' 'h_hcond15' 'h_hcondn6'\n",
      " 'h_hcond6' 'h_hcondn2' 'h_hcond19' 'h_hcondn11' 'h_hcond13' 'h_hcondn18'\n",
      " 'h_hcondn15' 'h_hcond5' 'h_hcond1' 'h_hcondn1' 'h_hcond17' 'i_hcond9'\n",
      " 'i_hcondn17' 'i_hcond3' 'i_hcondn10' 'i_hcondn11' 'i_hcondn18'\n",
      " 'i_hcondn13' 'i_hcond6' 'i_hcond13' 'i_hcondn1' 'i_hcond19' 'i_hcond12'\n",
      " 'i_hcond5' 'i_hcondn6' 'i_hcondn14' 'i_hcondn15' 'i_hcond15' 'i_hcondn19'\n",
      " 'i_hcond7' 'i_hcondn5' 'i_hcondn8' 'i_hcond18' 'i_hcondn3' 'i_hcond1'\n",
      " 'i_hcond4' 'i_hcond11' 'i_hcondn7' 'i_hcondn2' 'i_hcond10' 'i_hcondn4'\n",
      " 'i_hcond14' 'i_hcondn16' 'i_hcondn12' 'i_hcond16' 'i_hcondn9' 'i_hcond2'\n",
      " 'i_hcond8' 'i_hcond17' 'j_hcond5' 'j_hcond18' 'j_hcond19' 'j_hcond16'\n",
      " 'j_hcond12' 'j_hcond8' 'j_hcond21' 'j_hcond15' 'j_hcond2' 'j_hcond1'\n",
      " 'j_hcond13' 'j_hcond3' 'j_hcond11' 'j_hcond4' 'j_hcond7' 'j_hcond6'\n",
      " 'j_hcond10' 'j_hcond22' 'j_hcond14' 'k_hcond12' 'k_hcondnew2' 'k_hcond19'\n",
      " 'k_hcond15' 'k_hcondnew22' 'k_hcondnew10' 'k_hcondnew11' 'k_hcondnew14'\n",
      " 'k_hcond4' 'k_hcond13' 'k_hcond5' 'k_hcondnew6' 'k_hcondnew15'\n",
      " 'k_hcondnew16' 'k_hcond7' 'k_hcondnew8' 'k_hcond3' 'k_hcondnew7'\n",
      " 'k_hcond10' 'k_hcondnew12' 'k_hcondnew19' 'k_hcondnew4' 'k_hcond22'\n",
      " 'k_hcond2' 'k_hcond14' 'k_hcondnew1' 'k_hcondnew13' 'k_hcondnew5'\n",
      " 'k_hcond18' 'k_hcond6' 'k_hcond16' 'k_hcond1' 'k_hcondnew3' 'k_hcond8'\n",
      " 'k_hcondnew21' 'k_hcond11' 'k_hcond21' 'l_hcond18' 'l_hcond19'\n",
      " 'l_hcond10' 'l_hcondnew6' 'l_hcond3' 'l_hcond16' 'l_hcondnew8'\n",
      " 'l_hcondnew19' 'l_hcondnew1' 'l_hcondnew22' 'l_hcond5' 'l_hcond7'\n",
      " 'l_hcond2' 'l_hcondnew15' 'l_hcondnew16' 'l_hcondnew11' 'l_hcondnew13'\n",
      " 'l_hcond21' 'l_hcond4' 'l_hcond11' 'l_hcondnew5' 'l_hcond15'\n",
      " 'l_hcondnew10' 'l_hcondnew14' 'l_hcond12' 'l_hcondnew3' 'l_hcondnew7'\n",
      " 'l_hcond1' 'l_hcond22' 'l_hcondnew12' 'l_hcond8' 'l_hcondnew4'\n",
      " 'l_hcond13' 'l_hcond6' 'l_hcond14' 'l_hcondnew21' 'l_hcondnew2'\n",
      " 'm_hcond3' 'm_hcondnew7' 'm_hcondnew1' 'm_hcondnew14' 'm_hcond1'\n",
      " 'm_hcond4' 'm_hcondnew22' 'm_hcond10' 'm_hcondnew19' 'm_hcondnew12'\n",
      " 'm_hcond6' 'm_hcondnew10' 'm_hcond16' 'm_hcond19' 'm_hcond14' 'm_hcond11'\n",
      " 'm_hcond7' 'm_hcond13' 'm_hcondnew3' 'm_hcondnew2' 'm_hcondnew4'\n",
      " 'm_hcondnew11' 'm_hcondnew16' 'm_hcond8' 'm_hcondnew5' 'm_hcondnew13'\n",
      " 'm_hcondnew6' 'm_hcond21' 'm_hcond18' 'm_hcond12' 'm_hcond15'\n",
      " 'm_hcondnew8' 'm_hcondnew15' 'm_hcond2' 'm_hcond5' 'm_hcondnew21']\n",
      "Unique values in column 'value': [  0.   1.  -7.  -2.  -9.  -1.  nan  -8. -10.]\n",
      "  missing (-9) is present in column 'value'\n",
      "  proxy (-7) is present in column 'value'\n",
      "  refusal (-2) is present in column 'value'\n",
      "  don't know (-1) is present in column 'value'\n",
      "  not mentioned (0) is present in column 'value'\n",
      "  mentioned (1) is present in column 'value'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the long panel data from the Stata file\n",
    "long_panel_data_path = '/Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/Data/long_panel_ukhls_hcond_data.dta'\n",
    "long_panel_data = pd.read_stata(long_panel_data_path)\n",
    "\n",
    "# Define the special codes to check\n",
    "special_codes = {\n",
    "    'missing': -9,\n",
    "    'proxy': -7,\n",
    "    'refusal': -2,\n",
    "    'don\\'t know': -1,\n",
    "    'not mentioned': 0,\n",
    "    'mentioned': 1\n",
    "}\n",
    "\n",
    "# Function to check special codes in each variable\n",
    "def check_special_codes(df, special_codes):\n",
    "    for column in df.columns:\n",
    "        if column not in ['pidp', 'wave', 'variable']:\n",
    "            unique_values = df[column].unique()\n",
    "            print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "            for code_name, code_value in special_codes.items():\n",
    "                if code_value in unique_values:\n",
    "                    print(f\"  {code_name} ({code_value}) is present in column '{column}'\")\n",
    "                else:\n",
    "                    print(f\"  {code_name} ({code_value}) is NOT present in column '{column}'\")\n",
    "        else:\n",
    "            unique_values = df[column].unique()\n",
    "            print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "\n",
    "# Check for special codes in the long panel dataset\n",
    "check_special_codes(long_panel_data, special_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New approach to include the disdif and hcond along with age and death value in the long panel format: \n",
    "1. Load the xhhrel.dta file to get the death information.\n",
    "2. Merge the death information with the main dataset.\n",
    "3. Load the disdif variables from each wave and combine them with the existing health condition data.\n",
    "4. Calculate the frailty index using the combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
