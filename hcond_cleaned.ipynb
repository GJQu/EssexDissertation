{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Condition using 'hcond' and 'hcondnew'\n",
    "### By Gavin Qu - May 23rd 2024\n",
    "#### Data Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tEncode hcond and new healthcond variables correctly \n",
    "-\tNote that individuals are asked about pre-existing health conditions on their first interview in the UKHLS – the hcond (i) variable, where i codes different conditions – and then asked whether they have developed new conditions in subsequent interviews – the hcondn(i) variable in waves 1-9 and hcondnew(i) in waves 10 onwards.\n",
    "-\thcond in wave 1 and new entrants for succeeding waves, hcondn in wave 1-9, hcondnew in wave 10-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, hcond1-19 has 1, 3-13 waves, and it's for new interviewees only. While hcondn1-19 have 2-9 waves asking the existing interviewees about newly devloped conditions, and hcondnew1-19 have wave 9-13 for the same questions. \n",
    "hcond21 and hcondnew21 only exist from wave 10-13, while hcondnew22 only exist from 10-13. \n",
    "\n",
    "'dcsedfl_dv' is death data, but it's onyl 50% accurate when it comes to health mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/a_indresp.dta\n",
      "Available columns in a: {'a_hcond6', 'a_hcond12', 'a_hcond14', 'a_hcond10', 'a_hcond8', 'a_hcond4', 'a_hcond2', 'a_hcond7', 'a_hcond9', 'a_hcond11', 'a_hcond13', 'a_hcond15', 'a_hcond16', 'a_hcond5', 'a_hcond17', 'a_hcond3', 'pidp', 'a_hcond1'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/b_indresp.dta\n",
      "Available columns in b: {'b_hcondn11', 'b_hcondn8', 'b_hcondn10', 'b_hcondn5', 'b_hcondn13', 'b_hcondn2', 'b_hcondn4', 'b_hcondn16', 'b_hcondn7', 'b_hcondn9', 'b_hcondn15', 'b_hcondn3', 'b_hcondn14', 'b_hcondn12', 'b_hcondn17', 'b_hcondn1', 'pidp', 'b_hcondn6'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/c_indresp.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_73737/3566191621.py:28: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  wave_data = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in c: {'c_hcond9', 'c_hcondn9', 'c_hcondn13', 'c_hcondn2', 'c_hcond17', 'c_hcondn5', 'c_hcond11', 'c_hcondn3', 'c_hcond2', 'c_hcond8', 'c_hcondn14', 'c_hcond12', 'c_hcond3', 'c_hcond16', 'c_hcond5', 'c_hcondn6', 'c_hcondn15', 'c_hcondn1', 'c_hcond4', 'c_hcond6', 'c_hcond13', 'c_hcondn4', 'c_hcondn11', 'c_hcondn16', 'c_hcond15', 'c_hcondn12', 'c_hcondn17', 'c_hcondn8', 'c_hcond14', 'c_hcondn10', 'c_hcond10', 'c_hcondn7', 'pidp', 'c_hcond1', 'c_hcond7'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/d_indresp.dta\n",
      "Available columns in d: {'d_hcond8', 'd_hcond3', 'd_hcond10', 'd_hcond1', 'd_hcond13', 'd_hcond14', 'd_hcondn12', 'd_hcondn13', 'd_hcond16', 'd_hcond12', 'd_hcond11', 'pidp', 'd_hcond15', 'd_hcondn11', 'd_hcondn5', 'd_hcond9', 'd_hcondn16', 'd_hcond6', 'd_hcondn9', 'd_hcondn1', 'd_hcondn6', 'd_hcond4', 'd_hcondn7', 'd_hcondn15', 'd_hcondn2', 'd_hcondn17', 'd_hcondn10', 'd_hcondn8', 'd_hcondn3', 'd_hcondn4', 'd_hcond2', 'd_hcond17', 'd_hcondn14', 'd_hcond5', 'd_hcond7'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/e_indresp.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_73737/3566191621.py:28: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  wave_data = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in e: {'e_hcond6', 'e_hcond7', 'e_hcondn12', 'e_hcond5', 'e_hcondn1', 'e_hcond8', 'e_hcond2', 'e_hcondn15', 'e_hcondn3', 'e_hcond9', 'e_hcond11', 'e_hcondn4', 'e_hcondn10', 'e_hcond17', 'e_hcond1', 'e_hcondn7', 'e_hcondn16', 'e_hcond16', 'e_hcond3', 'e_hcondn5', 'e_hcondn11', 'e_hcondn14', 'e_hcondn9', 'e_hcond15', 'e_hcond10', 'e_hcond12', 'e_hcond4', 'e_hcond14', 'e_hcondn17', 'e_hcondn13', 'e_hcond13', 'e_hcondn6', 'e_hcondn2', 'e_hcondn8', 'pidp'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/f_indresp.dta\n",
      "Available columns in f: {'f_hcond17', 'f_hcondn11', 'f_hcondn13', 'f_hcondn15', 'f_hcond18', 'f_hcond4', 'f_hcondn10', 'f_hcondn14', 'f_hcond14', 'f_hcondn6', 'f_hcondn1', 'f_hcond13', 'f_hcond11', 'f_hcond7', 'f_hcond16', 'f_hcondn7', 'f_hcond1', 'f_hcondn18', 'f_hcondn16', 'f_hcond12', 'f_hcondn3', 'f_hcondn4', 'f_hcondn5', 'f_hcond8', 'f_hcond15', 'f_hcond2', 'f_hcondn9', 'f_hcond3', 'f_hcond6', 'f_hcondn17', 'f_hcondn2', 'f_hcond9', 'f_hcondn12', 'f_hcondn8', 'f_hcond5', 'pidp', 'f_hcond10'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/g_indresp.dta\n",
      "Available columns in g: {'g_hcondn3', 'g_hcond15', 'g_hcondn10', 'g_hcond6', 'g_hcond9', 'g_hcondn2', 'g_hcondn4', 'g_hcond10', 'g_hcond18', 'g_hcondn19', 'g_hcond4', 'g_hcond13', 'g_hcondn14', 'g_hcond16', 'g_hcondn1', 'g_hcondn6', 'g_hcond5', 'g_hcond17', 'g_hcondn8', 'g_hcondn15', 'g_hcondn18', 'g_hcondn13', 'g_hcondn9', 'g_hcondn12', 'g_hcondn17', 'g_hcond14', 'g_hcond11', 'g_hcond1', 'g_hcond2', 'g_hcond3', 'g_hcondn5', 'g_hcondn16', 'g_hcondn7', 'g_hcond19', 'g_hcond8', 'g_hcond12', 'pidp', 'g_hcondn11', 'g_hcond7'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/h_indresp.dta\n",
      "Available columns in h: {'h_hcond13', 'h_hcondn14', 'h_hcond6', 'h_hcond11', 'h_hcond14', 'h_hcond9', 'h_hcond15', 'h_hcondn5', 'h_hcondn4', 'h_hcondn13', 'h_hcond19', 'h_hcond1', 'h_hcondn10', 'h_hcondn6', 'h_hcond16', 'h_hcondn8', 'h_hcond5', 'h_hcond7', 'h_hcondn17', 'h_hcondn15', 'h_hcondn12', 'h_hcond4', 'h_hcond17', 'h_hcondn3', 'h_hcondn9', 'h_hcond10', 'h_hcondn1', 'h_hcondn16', 'h_hcond3', 'h_hcond12', 'h_hcond18', 'h_hcondn11', 'h_hcondn18', 'h_hcondn2', 'h_hcondn7', 'h_hcond2', 'h_hcond8', 'pidp', 'h_hcondn19'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/i_indresp.dta\n",
      "Available columns in i: {'i_hcondn6', 'i_hcond5', 'i_hcond18', 'i_hcond4', 'i_hcondn4', 'i_hcondn11', 'i_hcondn3', 'i_hcondn17', 'i_hcond17', 'i_hcond14', 'i_hcond9', 'i_hcond3', 'i_hcond12', 'i_hcond11', 'i_hcond13', 'i_hcondn1', 'i_hcondn16', 'i_hcondn9', 'i_hcondn5', 'i_hcondn18', 'i_hcond16', 'i_hcond8', 'i_hcondn19', 'i_hcond10', 'i_hcondn2', 'i_hcondn10', 'i_hcond7', 'i_hcondn12', 'i_hcond1', 'i_hcondn7', 'i_hcond15', 'i_hcondn15', 'i_hcondn8', 'i_hcondn13', 'i_hcondn14', 'i_hcond19', 'i_hcond2', 'pidp', 'i_hcond6'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/j_indresp.dta\n",
      "Available columns in j: {'j_hcond13', 'j_hcond19', 'j_hcond16', 'j_hcond5', 'j_hcond10', 'j_hcond2', 'j_hcond4', 'j_hcond18', 'j_hcond21', 'j_hcond3', 'j_hcond22', 'j_hcond6', 'j_hcond15', 'j_hcond8', 'j_hcond1', 'j_hcond11', 'j_hcond12', 'j_hcond7', 'pidp', 'j_hcond14'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/k_indresp.dta\n",
      "Available columns in k: {'k_hcondnew14', 'k_hcondnew10', 'k_hcond5', 'k_hcondnew15', 'k_hcondnew16', 'k_hcond13', 'k_hcondnew2', 'k_hcondnew7', 'k_hcondnew1', 'k_hcondnew22', 'k_hcond10', 'k_hcond7', 'k_hcondnew21', 'k_hcond18', 'k_hcond6', 'k_hcondnew11', 'k_hcondnew19', 'k_hcond22', 'k_hcond3', 'k_hcond14', 'k_hcond12', 'k_hcond21', 'k_hcond8', 'k_hcondnew3', 'k_hcondnew8', 'k_hcondnew13', 'k_hcond19', 'k_hcond4', 'k_hcondnew6', 'k_hcond2', 'k_hcondnew12', 'k_hcond1', 'k_hcondnew4', 'k_hcond15', 'k_hcond16', 'k_hcondnew5', 'pidp', 'k_hcond11'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/l_indresp.dta\n",
      "Available columns in l: {'l_hcondnew11', 'l_hcondnew21', 'l_hcondnew8', 'l_hcond8', 'l_hcondnew19', 'l_hcond11', 'l_hcond7', 'l_hcond12', 'l_hcondnew14', 'l_hcondnew12', 'l_hcond2', 'l_hcond10', 'l_hcond13', 'l_hcondnew6', 'l_hcondnew10', 'l_hcondnew13', 'l_hcondnew16', 'l_hcond21', 'l_hcondnew4', 'l_hcond22', 'l_hcondnew7', 'l_hcond3', 'l_hcond5', 'l_hcondnew2', 'l_hcond4', 'l_hcond19', 'l_hcond16', 'l_hcondnew3', 'l_hcond1', 'l_hcondnew5', 'l_hcondnew22', 'l_hcond14', 'l_hcond6', 'l_hcondnew15', 'l_hcond18', 'l_hcondnew1', 'l_hcond15', 'pidp'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/m_indresp.dta\n",
      "Available columns in m: {'m_hcond4', 'm_hcondnew10', 'm_hcond1', 'm_hcond21', 'm_hcondnew1', 'm_hcond18', 'm_hcondnew12', 'm_hcond13', 'm_hcondnew11', 'm_hcondnew15', 'm_hcond15', 'm_hcondnew7', 'm_hcondnew2', 'm_hcondnew5', 'm_hcond19', 'm_hcond14', 'm_hcondnew13', 'm_hcond10', 'm_hcond7', 'm_hcondnew8', 'm_hcond8', 'm_hcond2', 'm_hcond5', 'm_hcondnew6', 'm_hcond3', 'm_hcond6', 'm_hcondnew4', 'm_hcondnew19', 'm_hcond16', 'm_hcondnew14', 'm_hcondnew22', 'm_hcondnew21', 'm_hcondnew3', 'm_hcondnew16', 'm_hcond12', 'pidp', 'm_hcond11'}\n",
      "   a_hcond6  a_hcond12  a_hcond14  a_hcond10  a_hcond8  a_hcond4  a_hcond2  \\\n",
      "0       0.0        0.0        0.0        0.0       0.0       0.0       0.0   \n",
      "1       0.0        0.0        0.0        0.0       0.0       0.0       0.0   \n",
      "2       0.0        0.0        0.0        0.0       0.0       0.0       0.0   \n",
      "3       0.0        0.0        0.0        0.0       0.0       0.0       0.0   \n",
      "4       0.0        0.0        0.0        0.0       0.0       0.0       1.0   \n",
      "\n",
      "   a_hcond7  a_hcond9  a_hcond11  ...  m_hcondnew4  m_hcondnew19  m_hcond16  \\\n",
      "0       0.0       0.0        0.0  ...          NaN           NaN        NaN   \n",
      "1       0.0       0.0        0.0  ...          NaN           NaN        NaN   \n",
      "2       0.0       0.0        0.0  ...          NaN           NaN        NaN   \n",
      "3       0.0       0.0        0.0  ...          NaN           NaN        NaN   \n",
      "4       0.0       0.0        1.0  ...          NaN           NaN        NaN   \n",
      "\n",
      "   m_hcondnew14  m_hcondnew22  m_hcondnew21  m_hcondnew3  m_hcondnew16  \\\n",
      "0           NaN           NaN           NaN          NaN           NaN   \n",
      "1           NaN           NaN           NaN          NaN           NaN   \n",
      "2           NaN           NaN           NaN          NaN           NaN   \n",
      "3           NaN           NaN           NaN          NaN           NaN   \n",
      "4           NaN           NaN           NaN          NaN           NaN   \n",
      "\n",
      "  m_hcond12  m_hcond11  \n",
      "0       NaN        NaN  \n",
      "1       NaN        NaN  \n",
      "2       NaN        NaN  \n",
      "3       NaN        NaN  \n",
      "4       NaN        NaN  \n",
      "\n",
      "[5 rows x 417 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Base directory containing the data files\n",
    "base_dir = '/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls'\n",
    "\n",
    "# List of base variable names to extract, including 'pidp'\n",
    "base_variables = [\n",
    "    'pidp', 'hcond1', 'hcond2', 'hcond3', 'hcond4', 'hcond5', 'hcond6', 'hcond7',\n",
    "    'hcond8', 'hcond9', 'hcond10', 'hcond11', 'hcond12', 'hcond13', 'hcond14',\n",
    "    'hcond15', 'hcond16', 'hcond17', 'hcond18', 'hcond19', 'hcond21', 'hcond22',\n",
    "    'hcondn1', 'hcondn2', 'hcondn3', 'hcondn4', 'hcondn5', 'hcondn6', 'hcondn7',\n",
    "    'hcondn8', 'hcondn9', 'hcondn10', 'hcondn11', 'hcondn12', 'hcondn13', 'hcondn14',\n",
    "    'hcondn15', 'hcondn16', 'hcondn17', 'hcondn18', 'hcondn19', 'hcondnew1', 'hcondnew2',\n",
    "    'hcondnew3', 'hcondnew4', 'hcondnew5', 'hcondnew6', 'hcondnew7', 'hcondnew8',\n",
    "    'hcondnew10', 'hcondnew11', 'hcondnew12', 'hcondnew13', 'hcondnew14', 'hcondnew15',\n",
    "    'hcondnew16', 'hcondnew19', 'hcondnew21', 'hcondnew22'\n",
    "]\n",
    "\n",
    "# Wave prefixes from 'a' to 'm'\n",
    "wave_prefixes = [chr(i) for i in range(ord('a'), ord('n'))]\n",
    "\n",
    "# Function to load and filter wave data\n",
    "def load_wave_data(wave_prefix, base_dir, base_variables):\n",
    "    file_path = os.path.join(base_dir, f'{wave_prefix}_indresp.dta')\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading data from {file_path}\")\n",
    "        wave_data = pd.read_stata(file_path, convert_categoricals=False)\n",
    "        \n",
    "        # Construct the actual variable names for the current wave\n",
    "        wave_variables = [f'{wave_prefix}_{var}' if var != 'pidp' else var for var in base_variables]\n",
    "        \n",
    "        # Find the intersection of desired variables and available columns\n",
    "        available_columns = set(wave_variables).intersection(wave_data.columns)\n",
    "        print(f\"Available columns in {wave_prefix}: {available_columns}\")\n",
    "        \n",
    "        # Select only the available columns\n",
    "        if available_columns:\n",
    "            selected_data = wave_data[list(available_columns)].copy()\n",
    "            selected_data['wave'] = wave_prefix\n",
    "            return selected_data\n",
    "    return None\n",
    "\n",
    "# List to store data from each wave\n",
    "all_waves_data = []\n",
    "\n",
    "# Loop through wave prefixes\n",
    "for prefix in wave_prefixes:\n",
    "    wave_data = load_wave_data(prefix, base_dir, base_variables)\n",
    "    if wave_data is not None:\n",
    "        all_waves_data.append(wave_data)\n",
    "\n",
    "# Check if we have any data\n",
    "if all_waves_data:\n",
    "    # Combine all waves into a single DataFrame\n",
    "    combined_data = pd.concat(all_waves_data, ignore_index=True)\n",
    "\n",
    "    # Save the combined data to a CSV file\n",
    "    combined_data.to_csv('combined_ukhls_data.csv', index=False)\n",
    "\n",
    "    # Display the first few rows of the combined data\n",
    "    print(combined_data.head())\n",
    "else:\n",
    "    print(\"No data was loaded. Please check the file paths and variable names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save it in the long panel format based on wave and pidp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
