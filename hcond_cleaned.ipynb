{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Condition using 'hcond' and 'hcondnew'\n",
    "### By Gavin Qu - May 23rd 2024\n",
    "#### Data Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tEncode hcond and new healthcond variables correctly \n",
    "-\tNote that individuals are asked about pre-existing health conditions on their first interview in the UKHLS – the hcond (i) variable, where i codes different conditions – and then asked whether they have developed new conditions in subsequent interviews – the hcondn(i) variable in waves 1-9 and hcondnew(i) in waves 10 onwards.\n",
    "-\thcond in wave 1 and new entrants for succeeding waves, hcondn in wave 1-9, hcondnew in wave 10-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, hcond1-19 has 1, 3-13 waves, and it's for new interviewees only. While hcondn1-19 have 2-9 waves asking the existing interviewees about newly devloped conditions, and hcondnew1-19 have wave 9-13 for the same questions. \n",
    "hcond21 and hcondnew21 only exist from wave 10-13, while hcondnew22 only exist from 10-13. \n",
    "\n",
    "'dcsedfl_dv' is death data, but it's onyl 50% accurate when it comes to health mortality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of variables to extract\n",
    "variables = [\n",
    "    'hcond1', 'hcond2', 'hcond3', 'hcond4', 'hcond5', 'hcond6', 'hcond7',\n",
    "    'hcond8', 'hcond9', 'hcond10', 'hcond11', 'hcond12', 'hcond13', 'hcond14',\n",
    "    'hcond15', 'hcond16', 'hcond17', 'hcond18', 'hcond19', 'hcond21', 'hcond22',\n",
    "    'hcondn1', 'hcondn2', 'hcondn3', 'hcondn4', 'hcondn5', 'hcondn6', 'hcondn7',\n",
    "    'hcondn8', 'hcondn9', 'hcondn10', 'hcondn11', 'hcondn12', 'hcondn13', 'hcondn14',\n",
    "    'hcondn15', 'hcondn16', 'hcondn17', 'hcondn18', 'hcondn19', 'hcondnew1', 'hcondnew2',\n",
    "    'hcondnew3', 'hcondnew4', 'hcondnew5', 'hcondnew6', 'hcondnew7', 'hcondnew8',\n",
    "    'hcondnew10', 'hcondnew11', 'hcondnew12', 'hcondnew13', 'hcondnew14', 'hcondnew15',\n",
    "    'hcondnew16', 'hcondnew19', 'hcondnew21', 'hcondnew22'\n",
    "]\n",
    "\n",
    "# Function to load and filter wave data\n",
    "def load_wave_data(wave_prefix):\n",
    "    # Assuming each wave data is in a separate .dta file named 'wave_prefix.dta'\n",
    "    file_path = f'path_to_your_data/{wave_prefix}_data.dta'\n",
    "    wave_data = pd.read_stata(file_path, columns=variables)\n",
    "    wave_data['wave'] = wave_prefix\n",
    "    return wave_data\n",
    "\n",
    "# List to store data from each wave\n",
    "all_waves_data = []\n",
    "\n",
    "# Wave prefixes from 'a' to 'm'\n",
    "wave_prefixes = [chr(i) for i in range(ord('a'), ord('n'))]\n",
    "\n",
    "# Loop through wave prefixes\n",
    "for prefix in wave_prefixes:\n",
    "    wave_data = load_wave_data(prefix)\n",
    "    all_waves_data.append(wave_data)\n",
    "\n",
    "# Combine all waves into a single DataFrame\n",
    "combined_data = pd.concat(all_waves_data, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a CSV file\n",
    "combined_data.to_csv('combined_ukhls_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the combined data\n",
    "print(combined_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
