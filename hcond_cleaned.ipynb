{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Condition using 'hcond' and 'hcondnew'\n",
    "### By Gavin Qu - May 23rd 2024\n",
    "#### Data Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tEncode hcond and new healthcond variables correctly \n",
    "-\tNote that individuals are asked about pre-existing health conditions on their first interview in the UKHLS – the hcond (i) variable, where i codes different conditions – and then asked whether they have developed new conditions in subsequent interviews – the hcondn(i) variable in waves 1-9 and hcondnew(i) in waves 10 onwards.\n",
    "-\thcond in wave 1 and new entrants for succeeding waves, hcondn in wave 1-9, hcondnew in wave 10-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, hcond1-19 has 1, 3-13 waves, and it's for new interviewees only. While hcondn1-19 have 2-9 waves asking the existing interviewees about newly devloped conditions, and hcondnew1-19 have wave 9-13 for the same questions. \n",
    "hcond21 and hcondnew21 only exist from wave 10-13, while hcondnew22 only exist from 10-13. \n",
    "\n",
    "'dcsedfl_dv' is death data, but it's onyl 50% accurate when it comes to health mortality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether the long panel dataset you created has all the correct values, including the special codes like missing values, proxy, refusal, etc., you can use pandas to display the unique values for each variable. This way, you can verify that all expected values are present in the dataset.\n",
    "**Here's a script that:**\n",
    "- Loads the long panel dataset.\n",
    "- Displays the unique values for each variable.\n",
    "- Checks for the presence of the specified special codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'pidp': [  68001367   68004087   68006127 ... 1644552890 1644675410 1649095330]\n",
      "Unique values in column 'wave': ['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm']\n",
      "Unique values in column 'variable': ['a_hcond11' 'a_hcond13' 'a_hcond5' 'a_hcond7' 'a_hcond1' 'a_hcond15'\n",
      " 'a_hcond17' 'a_hcond9' 'a_hcond10' 'a_hcond14' 'a_hcond16' 'a_hcond12'\n",
      " 'a_hcond8' 'a_hcond3' 'a_hcond6' 'a_hcond2' 'a_hcond4' 'b_hcondn9'\n",
      " 'b_hcondn1' 'b_hcondn6' 'b_hcondn11' 'b_hcondn10' 'b_hcondn8' 'b_hcondn4'\n",
      " 'b_hcondn7' 'b_hcondn17' 'b_hcondn14' 'b_hcondn2' 'b_hcondn3' 'b_hcondn5'\n",
      " 'b_hcondn15' 'b_hcondn16' 'b_hcondn13' 'b_hcondn12' 'c_hcondn17'\n",
      " 'c_hcondn10' 'c_hcondn1' 'c_hcond11' 'c_hcond14' 'c_hcond3' 'c_hcondn13'\n",
      " 'c_hcondn15' 'c_hcond17' 'c_hcondn4' 'c_hcond1' 'c_hcond7' 'c_hcondn3'\n",
      " 'c_hcondn11' 'c_hcondn14' 'c_hcondn5' 'c_hcond5' 'c_hcond4' 'c_hcond9'\n",
      " 'c_hcondn12' 'c_hcondn2' 'c_hcond16' 'c_hcondn16' 'c_hcond6' 'c_hcond13'\n",
      " 'c_hcond15' 'c_hcond8' 'c_hcond2' 'c_hcondn9' 'c_hcond12' 'c_hcondn7'\n",
      " 'c_hcondn8' 'c_hcond10' 'c_hcondn6' 'd_hcondn8' 'd_hcondn10' 'd_hcond6'\n",
      " 'd_hcondn7' 'd_hcondn5' 'd_hcondn4' 'd_hcond13' 'd_hcond7' 'd_hcond3'\n",
      " 'd_hcond2' 'd_hcond15' 'd_hcond5' 'd_hcondn16' 'd_hcond14' 'd_hcondn17'\n",
      " 'd_hcondn3' 'd_hcond17' 'd_hcondn9' 'd_hcond1' 'd_hcondn15' 'd_hcondn12'\n",
      " 'd_hcondn2' 'd_hcond11' 'd_hcondn6' 'd_hcondn14' 'd_hcond8' 'd_hcond9'\n",
      " 'd_hcond12' 'd_hcondn13' 'd_hcondn11' 'd_hcond16' 'd_hcond4' 'd_hcond10'\n",
      " 'd_hcondn1' 'e_hcond9' 'e_hcondn8' 'e_hcondn4' 'e_hcondn6' 'e_hcondn1'\n",
      " 'e_hcondn2' 'e_hcondn3' 'e_hcondn14' 'e_hcond2' 'e_hcond8' 'e_hcond15'\n",
      " 'e_hcondn13' 'e_hcond7' 'e_hcond16' 'e_hcond13' 'e_hcond17' 'e_hcondn5'\n",
      " 'e_hcondn7' 'e_hcond11' 'e_hcondn11' 'e_hcond10' 'e_hcondn17' 'e_hcond12'\n",
      " 'e_hcond3' 'e_hcondn10' 'e_hcond4' 'e_hcondn15' 'e_hcond1' 'e_hcondn16'\n",
      " 'e_hcond14' 'e_hcond5' 'e_hcond6' 'e_hcondn12' 'e_hcondn9' 'f_hcond2'\n",
      " 'f_hcond11' 'f_hcondn12' 'f_hcond4' 'f_hcondn14' 'f_hcond3' 'f_hcond5'\n",
      " 'f_hcondn5' 'f_hcondn9' 'f_hcondn16' 'f_hcond10' 'f_hcondn2' 'f_hcondn10'\n",
      " 'f_hcond13' 'f_hcondn17' 'f_hcond1' 'f_hcondn7' 'f_hcond16' 'f_hcondn15'\n",
      " 'f_hcondn6' 'f_hcond8' 'f_hcondn18' 'f_hcond18' 'f_hcondn1' 'f_hcondn11'\n",
      " 'f_hcondn13' 'f_hcond6' 'f_hcondn3' 'f_hcond9' 'f_hcond17' 'f_hcondn4'\n",
      " 'f_hcondn8' 'f_hcond14' 'f_hcond7' 'f_hcond12' 'f_hcond15' 'g_hcond2'\n",
      " 'g_hcond19' 'g_hcondn3' 'g_hcond17' 'g_hcondn1' 'g_hcond4' 'g_hcondn13'\n",
      " 'g_hcond18' 'g_hcondn17' 'g_hcond14' 'g_hcond7' 'g_hcondn5' 'g_hcondn11'\n",
      " 'g_hcond11' 'g_hcond12' 'g_hcondn6' 'g_hcondn19' 'g_hcond1' 'g_hcond6'\n",
      " 'g_hcond5' 'g_hcond10' 'g_hcond13' 'g_hcondn8' 'g_hcond3' 'g_hcondn15'\n",
      " 'g_hcondn9' 'g_hcondn10' 'g_hcondn4' 'g_hcondn18' 'g_hcondn12'\n",
      " 'g_hcondn14' 'g_hcond8' 'g_hcond9' 'g_hcondn7' 'g_hcondn2' 'g_hcond15'\n",
      " 'g_hcond16' 'g_hcondn16' 'h_hcond10' 'h_hcondn8' 'h_hcondn12'\n",
      " 'h_hcondn19' 'h_hcond3' 'h_hcond7' 'h_hcond2' 'h_hcondn17' 'h_hcond8'\n",
      " 'h_hcondn9' 'h_hcond12' 'h_hcondn5' 'h_hcondn16' 'h_hcondn4' 'h_hcond18'\n",
      " 'h_hcondn7' 'h_hcondn10' 'h_hcond16' 'h_hcond4' 'h_hcond9' 'h_hcond11'\n",
      " 'h_hcondn14' 'h_hcondn3' 'h_hcond14' 'h_hcondn13' 'h_hcond15' 'h_hcondn6'\n",
      " 'h_hcond6' 'h_hcondn2' 'h_hcond19' 'h_hcondn11' 'h_hcond13' 'h_hcondn18'\n",
      " 'h_hcondn15' 'h_hcond5' 'h_hcond1' 'h_hcondn1' 'h_hcond17' 'i_hcond9'\n",
      " 'i_hcondn17' 'i_hcond3' 'i_hcondn10' 'i_hcondn11' 'i_hcondn18'\n",
      " 'i_hcondn13' 'i_hcond6' 'i_hcond13' 'i_hcondn1' 'i_hcond19' 'i_hcond12'\n",
      " 'i_hcond5' 'i_hcondn6' 'i_hcondn14' 'i_hcondn15' 'i_hcond15' 'i_hcondn19'\n",
      " 'i_hcond7' 'i_hcondn5' 'i_hcondn8' 'i_hcond18' 'i_hcondn3' 'i_hcond1'\n",
      " 'i_hcond4' 'i_hcond11' 'i_hcondn7' 'i_hcondn2' 'i_hcond10' 'i_hcondn4'\n",
      " 'i_hcond14' 'i_hcondn16' 'i_hcondn12' 'i_hcond16' 'i_hcondn9' 'i_hcond2'\n",
      " 'i_hcond8' 'i_hcond17' 'j_hcond5' 'j_hcond18' 'j_hcond19' 'j_hcond16'\n",
      " 'j_hcond12' 'j_hcond8' 'j_hcond21' 'j_hcond15' 'j_hcond2' 'j_hcond1'\n",
      " 'j_hcond13' 'j_hcond3' 'j_hcond11' 'j_hcond4' 'j_hcond7' 'j_hcond6'\n",
      " 'j_hcond10' 'j_hcond22' 'j_hcond14' 'k_hcond12' 'k_hcondnew2' 'k_hcond19'\n",
      " 'k_hcond15' 'k_hcondnew22' 'k_hcondnew10' 'k_hcondnew11' 'k_hcondnew14'\n",
      " 'k_hcond4' 'k_hcond13' 'k_hcond5' 'k_hcondnew6' 'k_hcondnew15'\n",
      " 'k_hcondnew16' 'k_hcond7' 'k_hcondnew8' 'k_hcond3' 'k_hcondnew7'\n",
      " 'k_hcond10' 'k_hcondnew12' 'k_hcondnew19' 'k_hcondnew4' 'k_hcond22'\n",
      " 'k_hcond2' 'k_hcond14' 'k_hcondnew1' 'k_hcondnew13' 'k_hcondnew5'\n",
      " 'k_hcond18' 'k_hcond6' 'k_hcond16' 'k_hcond1' 'k_hcondnew3' 'k_hcond8'\n",
      " 'k_hcondnew21' 'k_hcond11' 'k_hcond21' 'l_hcond18' 'l_hcond19'\n",
      " 'l_hcond10' 'l_hcondnew6' 'l_hcond3' 'l_hcond16' 'l_hcondnew8'\n",
      " 'l_hcondnew19' 'l_hcondnew1' 'l_hcondnew22' 'l_hcond5' 'l_hcond7'\n",
      " 'l_hcond2' 'l_hcondnew15' 'l_hcondnew16' 'l_hcondnew11' 'l_hcondnew13'\n",
      " 'l_hcond21' 'l_hcond4' 'l_hcond11' 'l_hcondnew5' 'l_hcond15'\n",
      " 'l_hcondnew10' 'l_hcondnew14' 'l_hcond12' 'l_hcondnew3' 'l_hcondnew7'\n",
      " 'l_hcond1' 'l_hcond22' 'l_hcondnew12' 'l_hcond8' 'l_hcondnew4'\n",
      " 'l_hcond13' 'l_hcond6' 'l_hcond14' 'l_hcondnew21' 'l_hcondnew2'\n",
      " 'm_hcond3' 'm_hcondnew7' 'm_hcondnew1' 'm_hcondnew14' 'm_hcond1'\n",
      " 'm_hcond4' 'm_hcondnew22' 'm_hcond10' 'm_hcondnew19' 'm_hcondnew12'\n",
      " 'm_hcond6' 'm_hcondnew10' 'm_hcond16' 'm_hcond19' 'm_hcond14' 'm_hcond11'\n",
      " 'm_hcond7' 'm_hcond13' 'm_hcondnew3' 'm_hcondnew2' 'm_hcondnew4'\n",
      " 'm_hcondnew11' 'm_hcondnew16' 'm_hcond8' 'm_hcondnew5' 'm_hcondnew13'\n",
      " 'm_hcondnew6' 'm_hcond21' 'm_hcond18' 'm_hcond12' 'm_hcond15'\n",
      " 'm_hcondnew8' 'm_hcondnew15' 'm_hcond2' 'm_hcond5' 'm_hcondnew21']\n",
      "Unique values in column 'value': [  0.   1.  -7.  -2.  -9.  -1.  nan  -8. -10.]\n",
      "  missing (-9) is present in column 'value'\n",
      "  proxy (-7) is present in column 'value'\n",
      "  refusal (-2) is present in column 'value'\n",
      "  don't know (-1) is present in column 'value'\n",
      "  not mentioned (0) is present in column 'value'\n",
      "  mentioned (1) is present in column 'value'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the long panel data from the Stata file\n",
    "long_panel_data_path = '/Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/Data/long_panel_ukhls_hcond_data.dta'\n",
    "long_panel_data = pd.read_stata(long_panel_data_path)\n",
    "\n",
    "# Define the special codes to check\n",
    "special_codes = {\n",
    "    'missing': -9,\n",
    "    'proxy': -7,\n",
    "    'refusal': -2,\n",
    "    'don\\'t know': -1,\n",
    "    'not mentioned': 0,\n",
    "    'mentioned': 1\n",
    "}\n",
    "\n",
    "# Function to check special codes in each variable\n",
    "def check_special_codes(df, special_codes):\n",
    "    for column in df.columns:\n",
    "        if column not in ['pidp', 'wave', 'variable']:\n",
    "            unique_values = df[column].unique()\n",
    "            print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "            for code_name, code_value in special_codes.items():\n",
    "                if code_value in unique_values:\n",
    "                    print(f\"  {code_name} ({code_value}) is present in column '{column}'\")\n",
    "                else:\n",
    "                    print(f\"  {code_name} ({code_value}) is NOT present in column '{column}'\")\n",
    "        else:\n",
    "            unique_values = df[column].unique()\n",
    "            print(f\"Unique values in column '{column}': {unique_values}\")\n",
    "\n",
    "# Check for special codes in the long panel dataset\n",
    "check_special_codes(long_panel_data, special_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New approach to include the disdif and hcond along with age and death value in the long panel format: \n",
    "1. Load the xhhrel.dta file to get the death information.\n",
    "2. Merge the death information with the main dataset.\n",
    "3. Load the disdif variables from each wave and combine them with the existing health condition data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/a_indresp.dta\n",
      "Available columns in a: {'a_disdif2', 'a_disdif6', 'pidp', 'a_disdif11', 'a_hcond12', 'a_disdif9', 'a_hcond15', 'a_hcond5', 'a_hcond13', 'a_disdif1', 'a_hcond14', 'a_disdif4', 'a_hcond11', 'a_hcond8', 'a_disdif10', 'a_hcond2', 'a_disdif7', 'a_hcond7', 'a_hcond9', 'a_disdif3', 'a_hcond1', 'a_hcond6', 'a_hcond16', 'a_hcond4', 'a_disdif5', 'a_hcond10', 'a_hcond17', 'a_disdif8', 'a_hcond3', 'a_age_dv'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/b_indresp.dta\n",
      "Available columns in b: {'b_disdif11', 'b_hcondn13', 'pidp', 'b_disdif1', 'b_disdif4', 'b_disdif9', 'b_hcondn12', 'b_hcondn15', 'b_disdif2', 'b_hcondn8', 'b_disdif7', 'b_hcondn16', 'b_hcondn5', 'b_disdif3', 'b_hcondn17', 'b_hcondn11', 'b_hcondn14', 'b_disdif6', 'b_hcondn2', 'b_age_dv', 'b_hcondn4', 'b_hcondn6', 'b_hcondn1', 'b_hcondn3', 'b_disdif8', 'b_hcondn10', 'b_hcondn9', 'b_disdif5', 'b_hcondn7', 'b_disdif10'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/c_indresp.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_92328/170927490.py:34: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  wave_data = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in c: {'c_hcondn5', 'c_hcond10', 'c_hcond17', 'c_disdif6', 'pidp', 'c_hcondn12', 'c_disdif4', 'c_disdif3', 'c_disdif10', 'c_hcondn1', 'c_hcond14', 'c_hcondn11', 'c_hcondn16', 'c_disdif11', 'c_hcond5', 'c_age_dv', 'c_hcond1', 'c_hcond2', 'c_hcond6', 'c_disdif5', 'c_hcondn10', 'c_hcond13', 'c_hcondn13', 'c_disdif7', 'c_disdif8', 'c_disdif2', 'c_hcondn2', 'c_disdif1', 'c_hcondn6', 'c_disdif9', 'c_hcond11', 'c_hcondn14', 'c_hcond15', 'c_hcondn3', 'c_hcond4', 'c_hcond8', 'c_hcond16', 'c_hcond3', 'c_hcond12', 'c_hcondn4', 'c_hcondn8', 'c_hcondn17', 'c_hcond9', 'c_hcondn9', 'c_hcondn15', 'c_hcondn7', 'c_hcond7'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/d_indresp.dta\n",
      "Available columns in d: {'d_disdif11', 'd_hcond7', 'd_hcond13', 'd_age_dv', 'd_hcond4', 'pidp', 'd_disdif9', 'd_hcond3', 'd_hcond14', 'd_hcond1', 'd_disdif2', 'd_hcondn8', 'd_hcondn1', 'd_hcondn5', 'd_hcondn7', 'd_hcondn14', 'd_disdif3', 'd_hcondn9', 'd_hcondn11', 'd_hcondn16', 'd_hcond16', 'd_hcondn10', 'd_hcondn13', 'd_hcondn2', 'd_disdif7', 'd_hcond12', 'd_disdif4', 'd_disdif6', 'd_disdif8', 'd_hcondn12', 'd_hcond15', 'd_disdif5', 'd_hcond9', 'd_hcond6', 'd_hcond10', 'd_hcond11', 'd_hcond17', 'd_disdif10', 'd_hcondn4', 'd_hcondn17', 'd_hcond2', 'd_hcond8', 'd_disdif1', 'd_hcondn3', 'd_hcondn6', 'd_hcond5', 'd_hcondn15'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/e_indresp.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_92328/170927490.py:34: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  wave_data = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in e: {'e_hcond5', 'e_hcondn11', 'e_hcond13', 'pidp', 'e_hcond4', 'e_hcond12', 'e_disdif11', 'e_hcond7', 'e_disdif9', 'e_hcondn14', 'e_hcondn3', 'e_hcondn6', 'e_disdif3', 'e_age_dv', 'e_disdif7', 'e_hcondn7', 'e_hcond6', 'e_disdif8', 'e_hcondn5', 'e_disdif1', 'e_hcond10', 'e_hcondn15', 'e_hcondn1', 'e_disdif4', 'e_hcond9', 'e_disdif6', 'e_hcondn17', 'e_hcond1', 'e_hcond11', 'e_hcondn16', 'e_hcondn12', 'e_hcond14', 'e_hcondn9', 'e_disdif5', 'e_hcond15', 'e_hcondn8', 'e_hcondn10', 'e_hcond8', 'e_hcond2', 'e_disdif10', 'e_hcond17', 'e_hcond3', 'e_hcond16', 'e_hcondn4', 'e_disdif2', 'e_hcondn13', 'e_hcondn2'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/f_indresp.dta\n",
      "Available columns in f: {'f_hcondn4', 'f_hcond4', 'pidp', 'f_hcondn16', 'f_disdif5', 'f_hcondn9', 'f_hcondn10', 'f_hcondn11', 'f_hcond7', 'f_disdif6', 'f_hcond16', 'f_hcondn1', 'f_hcondn13', 'f_disdif9', 'f_hcondn8', 'f_hcondn6', 'f_disdif4', 'f_age_dv', 'f_hcond2', 'f_disdif2', 'f_hcondn3', 'f_disdif8', 'f_hcond13', 'f_hcondn2', 'f_hcond17', 'f_hcond10', 'f_hcond8', 'f_hcondn17', 'f_disdif11', 'f_hcond5', 'f_hcond9', 'f_hcondn14', 'f_hcond14', 'f_hcond11', 'f_disdif10', 'f_hcond1', 'f_disdif3', 'f_hcond15', 'f_hcondn15', 'f_hcond12', 'f_hcond3', 'f_hcond6', 'f_hcondn5', 'f_disdif7', 'f_hcondn7', 'f_hcondn12', 'f_disdif1'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/g_indresp.dta\n",
      "Available columns in g: {'g_hcondn7', 'pidp', 'g_hcondn14', 'g_hcond3', 'g_hcondn4', 'g_disdif10', 'g_disdif11', 'g_hcond12', 'g_age_dv', 'g_disdif5', 'g_hcondn5', 'g_hcond7', 'g_disdif7', 'g_hcond9', 'g_hcondn12', 'g_disdif9', 'g_hcond2', 'g_hcondn1', 'g_hcond11', 'g_hcond17', 'g_hcondn6', 'g_hcondn11', 'g_hcondn8', 'g_hcondn17', 'g_disdif3', 'g_hcondn10', 'g_hcond6', 'g_disdif4', 'g_hcond5', 'g_hcond1', 'g_hcond15', 'g_disdif6', 'g_hcond4', 'g_hcond10', 'g_hcond14', 'g_hcondn15', 'g_hcond16', 'g_hcond13', 'g_hcondn2', 'g_hcondn3', 'g_hcondn13', 'g_hcond8', 'g_disdif8', 'g_hcondn9', 'g_disdif1', 'g_disdif2', 'g_hcondn16'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/h_indresp.dta\n",
      "Available columns in h: {'h_hcondn9', 'h_age_dv', 'h_disdif10', 'h_disdif11', 'h_hcondn13', 'h_hcondn2', 'h_hcond3', 'h_hcond2', 'pidp', 'h_hcondn14', 'h_hcondn3', 'h_hcondn16', 'h_disdif9', 'h_hcondn17', 'h_hcond1', 'h_hcond12', 'h_hcondn6', 'h_disdif5', 'h_hcond16', 'h_hcondn1', 'h_hcondn8', 'h_disdif3', 'h_hcondn5', 'h_hcond4', 'h_disdif2', 'h_hcond17', 'h_hcondn4', 'h_hcondn11', 'h_disdif6', 'h_hcond9', 'h_disdif7', 'h_hcond11', 'h_hcond10', 'h_disdif4', 'h_hcondn10', 'h_hcondn15', 'h_hcondn12', 'h_disdif8', 'h_hcondn7', 'h_hcond6', 'h_hcond8', 'h_hcond5', 'h_disdif1', 'h_hcond14', 'h_hcond7', 'h_hcond13', 'h_hcond15'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/i_indresp.dta\n",
      "Available columns in i: {'i_hcond15', 'i_hcondn9', 'pidp', 'i_hcondn10', 'i_hcondn17', 'i_hcond12', 'i_disdif10', 'i_hcondn1', 'i_disdif11', 'i_hcond17', 'i_disdif2', 'i_disdif9', 'i_hcondn6', 'i_hcondn15', 'i_hcond16', 'i_hcond7', 'i_hcondn16', 'i_hcond6', 'i_hcond11', 'i_hcondn7', 'i_hcond10', 'i_age_dv', 'i_hcondn8', 'i_hcond1', 'i_hcondn3', 'i_hcond9', 'i_disdif3', 'i_disdif7', 'i_disdif8', 'i_hcondn2', 'i_hcond2', 'i_hcond5', 'i_disdif4', 'i_hcondn4', 'i_hcondn14', 'i_hcondn12', 'i_hcondn5', 'i_hcond4', 'i_hcond14', 'i_hcondn11', 'i_hcondn13', 'i_hcond13', 'i_disdif5', 'i_hcond3', 'i_disdif1', 'i_hcond8', 'i_disdif6'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/j_indresp.dta\n",
      "Available columns in j: {'j_hcond3', 'j_hcond4', 'pidp', 'j_disdif3', 'j_disdif11', 'j_hcond11', 'j_hcond1', 'j_disdif4', 'j_hcond15', 'j_disdif1', 'j_disdif5', 'j_disdif6', 'j_hcond12', 'j_hcond2', 'j_hcond10', 'j_hcond16', 'j_hcond22', 'j_hcond6', 'j_disdif7', 'j_hcond8', 'j_hcond21', 'j_hcond13', 'j_hcond7', 'j_disdif8', 'j_disdif9', 'j_disdif10', 'j_age_dv', 'j_disdif2', 'j_hcond14', 'j_hcond5'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/k_indresp.dta\n",
      "Available columns in k: {'k_hcond12', 'k_hcondnew2', 'k_hcondnew10', 'k_disdif3', 'k_disdif11', 'k_hcond11', 'pidp', 'k_hcond13', 'k_disdif2', 'k_disdif4', 'k_hcond15', 'k_hcondnew1', 'k_hcondnew11', 'k_hcond21', 'k_hcond3', 'k_hcondnew14', 'k_hcondnew3', 'k_hcond14', 'k_disdif9', 'k_hcondnew7', 'k_hcond5', 'k_hcondnew5', 'k_disdif7', 'k_hcondnew4', 'k_hcond6', 'k_hcondnew12', 'k_disdif6', 'k_hcondnew6', 'k_hcond2', 'k_hcond10', 'k_hcondnew16', 'k_disdif1', 'k_hcondnew13', 'k_hcond7', 'k_disdif10', 'k_disdif8', 'k_hcond16', 'k_hcondnew8', 'k_hcondnew15', 'k_hcond4', 'k_hcond1', 'k_hcond8', 'k_disdif5', 'k_age_dv', 'k_hcond22'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/l_indresp.dta\n",
      "Available columns in l: {'l_hcond3', 'pidp', 'l_hcondnew4', 'l_disdif11', 'l_hcond4', 'l_hcondnew2', 'l_hcondnew1', 'l_hcondnew14', 'l_hcondnew16', 'l_disdif4', 'l_hcond14', 'l_hcond6', 'l_disdif3', 'l_hcondnew5', 'l_hcond1', 'l_hcondnew11', 'l_hcond12', 'l_disdif8', 'l_disdif7', 'l_hcond7', 'l_disdif6', 'l_hcondnew6', 'l_hcond21', 'l_hcondnew13', 'l_hcond8', 'l_hcondnew7', 'l_disdif10', 'l_disdif9', 'l_hcond11', 'l_disdif1', 'l_hcondnew3', 'l_hcond15', 'l_hcond5', 'l_hcond22', 'l_hcondnew12', 'l_disdif5', 'l_hcond16', 'l_hcond2', 'l_hcond13', 'l_disdif2', 'l_hcondnew8', 'l_hcond10', 'l_hcondnew10', 'l_age_dv', 'l_hcondnew15'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/m_indresp.dta\n",
      "Available columns in m: {'m_hcondnew8', 'm_hcondnew3', 'm_hcond1', 'm_disdif9', 'pidp', 'm_disdif2', 'm_hcondnew15', 'm_hcondnew16', 'm_hcond4', 'm_disdif7', 'm_hcond21', 'm_hcond6', 'm_hcond2', 'm_disdif6', 'm_age_dv', 'm_hcond8', 'm_disdif5', 'm_disdif11', 'm_hcondnew13', 'm_hcondnew14', 'm_hcond13', 'm_disdif4', 'm_disdif1', 'm_hcond15', 'm_hcondnew6', 'm_hcond10', 'm_hcondnew10', 'm_hcondnew12', 'm_hcond16', 'm_hcondnew1', 'm_hcond7', 'm_disdif8', 'm_hcond11', 'm_hcondnew7', 'm_hcondnew11', 'm_disdif3', 'm_hcond12', 'm_hcond14', 'm_hcondnew4', 'm_hcond5', 'm_hcond3', 'm_hcondnew5', 'm_hcondnew2', 'm_disdif10'}\n",
      "       pidp wave   variable  value\n",
      "0  68001367    a  a_disdif2   -8.0\n",
      "1  68004087    a  a_disdif2   -8.0\n",
      "2  68006127    a  a_disdif2    0.0\n",
      "3  68006135    a  a_disdif2   -8.0\n",
      "4  68006807    a  a_disdif2    1.0\n",
      "Combined data saved to /Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/Data/combined_ukhls_hcond_disdif_death_data.dta\n",
      "Long panel data saved to /Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/Data/long_panel_ukhls_hcond_disdif_death_data.dta\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Base directory containing the data files\n",
    "base_dir = '/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls'\n",
    "\n",
    "# List of base variable names to extract, including 'pidp'\n",
    "base_hcond_variables = [\n",
    "    'pidp', 'hcond1', 'hcond2', 'hcond3', 'hcond4', 'hcond5', 'hcond6', 'hcond7',\n",
    "    'hcond8', 'hcond9', 'hcond10', 'hcond11', 'hcond12', 'hcond13', 'hcond14',\n",
    "    'hcond15', 'hcond16', 'hcond17', 'hcond21', 'hcond22',\n",
    "    'hcondn1', 'hcondn2', 'hcondn3', 'hcondn4', 'hcondn5', 'hcondn6', 'hcondn7',\n",
    "    'hcondn8', 'hcondn9', 'hcondn10', 'hcondn11', 'hcondn12', 'hcondn13', 'hcondn14',\n",
    "    'hcondn15', 'hcondn16', 'hcondn17', 'hcondnew1', 'hcondnew2',\n",
    "    'hcondnew3', 'hcondnew4', 'hcondnew5', 'hcondnew6', 'hcondnew7', 'hcondnew8',\n",
    "    'hcondnew10', 'hcondnew11', 'hcondnew12', 'hcondnew13', 'hcondnew14', 'hcondnew15',\n",
    "    'hcondnew16'\n",
    "]\n",
    "\n",
    "base_disdif_variables = [f'disdif{i}' for i in range(1, 12)]\n",
    "age_variable = 'age_dv'\n",
    "\n",
    "# Combine all variable names to extract\n",
    "base_variables = ['pidp'] + base_hcond_variables[1:] + base_disdif_variables + [age_variable]\n",
    "\n",
    "# Wave prefixes from 'a' to 'm'\n",
    "wave_prefixes = [chr(i) for i in range(ord('a'), ord('n'))]\n",
    "\n",
    "# Function to load and filter wave data\n",
    "def load_wave_data(wave_prefix, base_dir, base_variables):\n",
    "    file_path = os.path.join(base_dir, f'{wave_prefix}_indresp.dta')\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading data from {file_path}\")\n",
    "        wave_data = pd.read_stata(file_path, convert_categoricals=False)\n",
    "        \n",
    "        # Construct the actual variable names for the current wave\n",
    "        wave_variables = [f'{wave_prefix}_{var}' if var != 'pidp' else var for var in base_variables]\n",
    "        \n",
    "        # Find the intersection of desired variables and available columns\n",
    "        available_columns = set(wave_variables).intersection(wave_data.columns)\n",
    "        print(f\"Available columns in {wave_prefix}: {available_columns}\")\n",
    "        \n",
    "        # Select only the available columns\n",
    "        if available_columns:\n",
    "            selected_data = wave_data[list(available_columns)].copy()\n",
    "            selected_data['wave'] = wave_prefix\n",
    "            return selected_data\n",
    "    return None\n",
    "\n",
    "# List to store data from each wave\n",
    "all_waves_data = []\n",
    "\n",
    "# Loop through wave prefixes\n",
    "for prefix in wave_prefixes:\n",
    "    wave_data = load_wave_data(prefix, base_dir, base_variables)\n",
    "    if wave_data is not None:\n",
    "        all_waves_data.append(wave_data)\n",
    "\n",
    "# Combine all waves into a single DataFrame\n",
    "if all_waves_data:\n",
    "    combined_data = pd.concat(all_waves_data, ignore_index=True)\n",
    "\n",
    "    # Load the death information from xhhrel.dta\n",
    "    death_file_path = os.path.join(base_dir, 'xhhrel.dta')\n",
    "    death_data = pd.read_stata(death_file_path, convert_categoricals=False)\n",
    "\n",
    "    # Select the pidp and death column\n",
    "    death_data = death_data[['pidp', 'dcsedfl_dv']]\n",
    "\n",
    "    # Merge the death information with the combined data\n",
    "    combined_data = combined_data.merge(death_data, on='pidp', how='left')\n",
    "\n",
    "    # Save the combined data with death information to a Stata file\n",
    "    output_dir = '/Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/Data'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    combined_data_path = os.path.join(output_dir, 'combined_ukhls_hcond_disdif_death_data.dta')\n",
    "    combined_data.to_stata(combined_data_path, write_index=False)\n",
    "\n",
    "    # Reshape the DataFrame into long panel format\n",
    "    id_vars = ['pidp', 'wave']  # Identifier variables\n",
    "    value_vars = [col for col in combined_data.columns if col not in id_vars and col not in ['dcsedfl_dv']]  # All other columns\n",
    "\n",
    "    # Melt the DataFrame\n",
    "    long_panel_data = pd.melt(combined_data, id_vars=id_vars, value_vars=value_vars,\n",
    "                              var_name='variable', value_name='value')\n",
    "\n",
    "    # Save the long panel data to a Stata file\n",
    "    long_panel_data_path = os.path.join(output_dir, 'long_panel_ukhls_hcond_disdif_death_data.dta')\n",
    "    long_panel_data.to_stata(long_panel_data_path, write_index=False)\n",
    "\n",
    "    # Display the first few rows of the long panel data\n",
    "    print(long_panel_data.head())\n",
    "\n",
    "    print(f\"Combined data saved to {combined_data_path}\")\n",
    "    print(f\"Long panel data saved to {long_panel_data_path}\")\n",
    "else:\n",
    "    print(\"No data was loaded. Please check the file paths and variable names.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
