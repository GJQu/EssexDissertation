{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hcondever variable and frailty index\n",
    "\n",
    "#### Gavin Qu, May 30th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/a_indresp.dta\n",
      "Available columns in a: {'a_disdif6', 'a_hcond15', 'a_disdif9', 'a_hcond3', 'a_hcond6', 'a_hcond14', 'a_disdif3', 'a_hcond1', 'a_disdif8', 'a_disdif11', 'a_hcond8', 'a_disdif7', 'a_hcond2', 'a_hcond10', 'a_hcond16', 'a_hcond9', 'a_disdif2', 'a_disdif1', 'pidp', 'a_hcond12', 'a_hcond4', 'a_disdif5', 'a_hcond5', 'a_hcond7', 'a_disdif10', 'a_hcond13', 'a_hcond17', 'a_disdif4', 'a_age_dv', 'a_hcond11'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/b_indresp.dta\n",
      "Available columns in b: {'b_hcondn9', 'b_hcondn10', 'b_disdif9', 'b_hcondn2', 'b_hcondn5', 'b_disdif8', 'b_hcondn16', 'b_hcondn13', 'b_hcondn7', 'b_hcondn8', 'b_hcondn12', 'b_hcondn14', 'b_hcondn6', 'b_hcondn15', 'b_age_dv', 'b_disdif10', 'b_disdif6', 'b_disdif4', 'b_disdif7', 'pidp', 'b_disdif2', 'b_disdif3', 'b_hcondn1', 'b_hcondn17', 'b_disdif5', 'b_hcondn3', 'b_hcondn4', 'b_hcondn11', 'b_disdif1', 'b_disdif11'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/c_indresp.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_52456/2409186563.py:33: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  wave_data = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in c: {'c_hcond2', 'c_disdif7', 'c_hcondn5', 'c_hcondn15', 'c_disdif1', 'c_hcondn1', 'c_hcondn4', 'c_hcond5', 'c_hcond9', 'c_disdif10', 'c_hcondn17', 'c_hcondn14', 'c_hcond12', 'c_hcondn16', 'c_hcondn10', 'c_hcondn13', 'c_hcond3', 'c_hcondn3', 'pidp', 'c_hcondn2', 'c_hcondn8', 'c_hcondn7', 'c_hcondn11', 'c_hcond14', 'c_disdif2', 'c_hcond17', 'c_hcond16', 'c_disdif3', 'c_hcond11', 'c_hcond6', 'c_hcond4', 'c_hcondn6', 'c_disdif8', 'c_hcond7', 'c_hcond13', 'c_disdif5', 'c_disdif11', 'c_hcondn12', 'c_disdif4', 'c_hcond10', 'c_hcond15', 'c_hcond1', 'c_age_dv', 'c_disdif9', 'c_hcond8', 'c_disdif6', 'c_hcondn9'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/d_indresp.dta\n",
      "Available columns in d: {'d_hcond4', 'd_disdif8', 'd_hcond14', 'd_hcond5', 'd_hcondn4', 'd_disdif10', 'd_hcondn12', 'd_disdif4', 'd_hcondn14', 'd_disdif3', 'd_hcond16', 'd_hcond13', 'd_hcond17', 'd_hcondn10', 'd_hcondn3', 'd_hcond15', 'd_hcond12', 'd_disdif11', 'd_hcondn2', 'd_hcondn6', 'd_hcond2', 'd_disdif7', 'd_hcond8', 'd_hcond9', 'd_age_dv', 'pidp', 'd_hcondn11', 'd_hcond1', 'd_hcondn17', 'd_disdif6', 'd_hcondn16', 'd_hcond3', 'd_hcondn9', 'd_disdif1', 'd_hcondn8', 'd_disdif9', 'd_hcond6', 'd_hcond10', 'd_hcond11', 'd_hcondn1', 'd_hcondn5', 'd_hcondn13', 'd_disdif5', 'd_hcond7', 'd_disdif2', 'd_hcondn7', 'd_hcondn15'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/e_indresp.dta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n2/8hz3y3r90rj63gkzgrl1hwg40000gn/T/ipykernel_52456/2409186563.py:33: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  wave_data = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in e: {'e_age_dv', 'e_hcondn5', 'e_hcondn7', 'e_hcond1', 'e_hcondn8', 'e_hcondn10', 'e_hcond6', 'e_hcond3', 'e_hcond14', 'e_disdif1', 'e_hcond16', 'e_hcondn14', 'e_hcond9', 'e_hcondn13', 'e_hcond4', 'e_hcond7', 'e_disdif9', 'e_hcondn16', 'e_disdif3', 'e_hcondn4', 'e_hcondn2', 'pidp', 'e_disdif6', 'e_hcondn11', 'e_hcondn9', 'e_disdif2', 'e_hcond15', 'e_hcond8', 'e_disdif5', 'e_hcond5', 'e_hcond17', 'e_hcondn1', 'e_hcondn12', 'e_hcondn17', 'e_disdif4', 'e_disdif11', 'e_hcond2', 'e_hcond12', 'e_hcondn3', 'e_disdif8', 'e_hcondn6', 'e_hcond13', 'e_disdif10', 'e_hcond10', 'e_hcondn15', 'e_hcond11', 'e_disdif7'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/f_indresp.dta\n",
      "Available columns in f: {'f_hcondn15', 'f_disdif8', 'f_hcond14', 'f_hcond9', 'f_disdif9', 'f_hcond11', 'f_hcondn14', 'f_hcondn11', 'f_disdif6', 'f_hcond16', 'f_hcondn7', 'f_disdif1', 'f_disdif11', 'f_hcond5', 'f_hcondn6', 'f_age_dv', 'f_disdif4', 'f_disdif2', 'f_hcond8', 'f_hcond13', 'f_hcondn4', 'f_disdif5', 'f_hcondn12', 'f_hcondn2', 'f_disdif7', 'f_disdif3', 'f_hcondn9', 'f_hcondn8', 'f_hcondn1', 'pidp', 'f_hcond3', 'f_hcond7', 'f_hcond1', 'f_hcond17', 'f_hcondn5', 'f_hcond2', 'f_hcond6', 'f_hcond10', 'f_hcondn16', 'f_hcond12', 'f_hcond4', 'f_disdif10', 'f_hcondn3', 'f_hcondn10', 'f_hcondn17', 'f_hcondn13', 'f_hcond15'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/g_indresp.dta\n",
      "Available columns in g: {'g_hcond1', 'g_hcond9', 'g_hcondn14', 'g_hcondn3', 'g_hcondn6', 'g_hcondn7', 'g_hcond12', 'g_disdif1', 'g_disdif4', 'g_hcondn15', 'g_hcondn5', 'g_disdif2', 'g_disdif10', 'g_hcond15', 'g_hcond13', 'g_disdif7', 'g_hcondn8', 'g_hcond8', 'g_hcondn12', 'g_hcondn13', 'g_hcond10', 'g_hcond7', 'g_disdif6', 'g_hcond14', 'pidp', 'g_hcond5', 'g_age_dv', 'g_hcondn10', 'g_hcondn11', 'g_disdif5', 'g_hcondn9', 'g_hcondn16', 'g_hcond16', 'g_disdif9', 'g_disdif8', 'g_hcond6', 'g_hcond4', 'g_hcond2', 'g_hcondn4', 'g_hcond3', 'g_hcondn17', 'g_hcondn2', 'g_disdif11', 'g_hcondn1', 'g_hcond11', 'g_hcond17', 'g_disdif3'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/h_indresp.dta\n",
      "Available columns in h: {'h_hcond7', 'h_hcond8', 'h_hcondn2', 'h_disdif7', 'h_hcondn14', 'h_disdif1', 'h_hcond12', 'h_disdif2', 'h_hcondn11', 'h_disdif3', 'h_hcondn12', 'h_hcondn9', 'h_hcond1', 'h_hcondn13', 'h_hcondn4', 'h_disdif6', 'h_disdif4', 'h_hcondn10', 'h_hcond15', 'h_hcondn15', 'h_hcond3', 'h_age_dv', 'h_disdif11', 'h_hcond13', 'h_hcondn1', 'h_hcondn16', 'h_hcondn6', 'h_hcond5', 'h_hcondn3', 'h_hcond11', 'h_disdif10', 'pidp', 'h_hcond10', 'h_hcond17', 'h_hcondn8', 'h_disdif9', 'h_hcondn17', 'h_hcond2', 'h_hcond9', 'h_disdif5', 'h_hcondn5', 'h_hcond16', 'h_hcond6', 'h_hcond4', 'h_disdif8', 'h_hcondn7', 'h_hcond14'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/i_indresp.dta\n",
      "Available columns in i: {'i_disdif5', 'i_hcond5', 'i_hcondn10', 'i_hcond9', 'i_hcondn8', 'i_hcondn16', 'i_hcondn9', 'i_disdif7', 'i_hcond14', 'i_hcondn1', 'i_hcondn17', 'i_disdif2', 'i_hcond1', 'i_disdif6', 'i_hcond17', 'i_hcond7', 'i_hcondn7', 'i_disdif10', 'i_hcond2', 'i_hcondn3', 'i_age_dv', 'i_disdif11', 'pidp', 'i_hcondn11', 'i_hcond13', 'i_hcond16', 'i_hcondn2', 'i_hcondn4', 'i_hcondn5', 'i_hcond12', 'i_hcond6', 'i_hcondn12', 'i_disdif3', 'i_hcondn13', 'i_hcond3', 'i_disdif8', 'i_hcond10', 'i_hcond11', 'i_hcond4', 'i_disdif9', 'i_disdif1', 'i_hcond15', 'i_disdif4', 'i_hcondn14', 'i_hcondn15', 'i_hcondn6', 'i_hcond8'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/j_indresp.dta\n",
      "Available columns in j: {'j_hcond14', 'j_hcond21', 'j_disdif7', 'j_hcond12', 'j_hcond5', 'j_age_dv', 'j_hcond10', 'j_hcond6', 'j_hcond4', 'j_disdif6', 'j_disdif5', 'j_hcond15', 'j_disdif2', 'j_hcond16', 'j_disdif10', 'j_disdif4', 'pidp', 'j_disdif1', 'j_hcond8', 'j_hcond11', 'j_hcond22', 'j_disdif8', 'j_disdif3', 'j_hcond7', 'j_disdif9', 'j_hcond2', 'j_hcond1', 'j_hcond3', 'j_hcond13', 'j_disdif11'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/k_indresp.dta\n",
      "Available columns in k: {'k_age_dv', 'k_disdif9', 'k_hcond8', 'k_disdif5', 'k_hcondnew3', 'k_hcondnew15', 'k_disdif3', 'k_hcond22', 'k_hcond10', 'k_hcond13', 'k_hcond14', 'k_hcondnew7', 'k_hcond6', 'k_hcondnew11', 'k_disdif2', 'k_hcond21', 'k_hcond3', 'k_disdif6', 'k_hcond1', 'k_disdif4', 'k_hcond11', 'k_hcond16', 'pidp', 'k_disdif1', 'k_hcond12', 'k_hcondnew1', 'k_hcondnew16', 'k_hcond5', 'k_hcondnew13', 'k_disdif10', 'k_disdif8', 'k_hcondnew5', 'k_hcondnew14', 'k_hcond15', 'k_hcondnew6', 'k_hcond2', 'k_disdif7', 'k_hcondnew2', 'k_disdif11', 'k_hcond7', 'k_hcondnew8', 'k_hcondnew10', 'k_hcondnew12', 'k_hcond4', 'k_hcondnew4'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/l_indresp.dta\n",
      "Available columns in l: {'l_hcond13', 'l_disdif4', 'l_hcondnew4', 'l_hcondnew2', 'l_hcondnew5', 'l_hcondnew11', 'l_hcond14', 'l_hcond10', 'l_hcondnew14', 'l_disdif2', 'l_hcondnew13', 'l_hcondnew15', 'l_hcond11', 'l_hcond16', 'l_hcondnew8', 'l_hcond15', 'l_hcondnew12', 'l_hcondnew16', 'l_hcondnew10', 'l_hcond8', 'l_disdif11', 'l_hcondnew3', 'l_hcond12', 'l_hcond1', 'l_age_dv', 'pidp', 'l_hcond7', 'l_hcondnew7', 'l_disdif6', 'l_hcond3', 'l_hcond6', 'l_disdif1', 'l_hcond22', 'l_hcondnew1', 'l_hcond2', 'l_disdif3', 'l_disdif9', 'l_hcond5', 'l_hcondnew6', 'l_hcond4', 'l_hcond21', 'l_disdif8', 'l_disdif5', 'l_disdif10', 'l_disdif7'}\n",
      "Loading data from /Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls/m_indresp.dta\n",
      "Available columns in m: {'m_disdif10', 'm_hcondnew11', 'm_hcond21', 'm_hcond14', 'm_hcond15', 'm_hcond16', 'm_hcond3', 'm_disdif5', 'm_disdif7', 'm_hcondnew13', 'm_hcondnew8', 'm_disdif4', 'm_hcond4', 'm_hcondnew10', 'm_age_dv', 'm_hcondnew5', 'm_hcondnew16', 'm_hcond6', 'm_hcond8', 'pidp', 'm_hcondnew12', 'm_hcond2', 'm_hcondnew2', 'm_disdif6', 'm_hcondnew14', 'm_hcond10', 'm_disdif1', 'm_disdif2', 'm_hcond1', 'm_hcondnew6', 'm_hcondnew15', 'm_disdif11', 'm_disdif3', 'm_hcondnew7', 'm_disdif9', 'm_hcond7', 'm_hcond11', 'm_hcond12', 'm_hcond13', 'm_hcondnew4', 'm_disdif8', 'm_hcond5', 'm_hcondnew1', 'm_hcondnew3'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Base directory containing the data files\n",
    "base_dir = '/Users/gavinqu/Desktop/School/Dissertation/UKDA-6614-stata/stata/stata13_se/ukhls'\n",
    "\n",
    "# List of base variable names to extract, including 'pidp'\n",
    "base_hcond_variables = [\n",
    "    'pidp', 'hcond1', 'hcond2', 'hcond3', 'hcond4', 'hcond5', 'hcond6', 'hcond7',\n",
    "    'hcond8', 'hcond9', 'hcond10', 'hcond11', 'hcond12', 'hcond13', 'hcond14',\n",
    "    'hcond15', 'hcond16', 'hcond17', 'hcond21', 'hcond22',\n",
    "    'hcondn1', 'hcondn2', 'hcondn3', 'hcondn4', 'hcondn5', 'hcondn6', 'hcondn7',\n",
    "    'hcondn8', 'hcondn9', 'hcondn10', 'hcondn11', 'hcondn12', 'hcondn13', 'hcondn14',\n",
    "    'hcondn15', 'hcondn16', 'hcondn17', 'hcondnew1', 'hcondnew2',\n",
    "    'hcondnew3', 'hcondnew4', 'hcondnew5', 'hcondnew6', 'hcondnew7', 'hcondnew8',\n",
    "    'hcondnew10', 'hcondnew11', 'hcondnew12', 'hcondnew13', 'hcondnew14', 'hcondnew15',\n",
    "    'hcondnew16'\n",
    "]\n",
    "\n",
    "base_disdif_variables = [f'disdif{i}' for i in range(1, 12)]\n",
    "\n",
    "# Combine all variable names to extract\n",
    "base_variables = ['pidp'] + base_hcond_variables[1:] + base_disdif_variables\n",
    "\n",
    "# Wave prefixes from 'a' to 'm'\n",
    "wave_prefixes = [chr(i) for i in range(ord('a'), ord('n'))]\n",
    "\n",
    "# Function to load and filter wave data\n",
    "def load_wave_data(wave_prefix, base_dir, base_variables):\n",
    "    file_path = os.path.join(base_dir, f'{wave_prefix}_indresp.dta')\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Loading data from {file_path}\")\n",
    "        wave_data = pd.read_stata(file_path, convert_categoricals=False)\n",
    "        \n",
    "        # Construct the actual variable names for the current wave\n",
    "        wave_variables = [f'{wave_prefix}_{var}' if var != 'pidp' else var for var in base_variables]\n",
    "        age_column = f'{wave_prefix}_age_dv'\n",
    "        wave_variables.append(age_column)\n",
    "        \n",
    "        # Find the intersection of desired variables and available columns\n",
    "        available_columns = set(wave_variables).intersection(wave_data.columns)\n",
    "        print(f\"Available columns in {wave_prefix}: {available_columns}\")\n",
    "        \n",
    "        # Select only the available columns\n",
    "        if available_columns:\n",
    "            selected_data = wave_data[list(available_columns)].copy()\n",
    "            selected_data['wave'] = wave_prefix\n",
    "            return selected_data\n",
    "    return None\n",
    "\n",
    "# List to store data from each wave\n",
    "all_waves_data = []\n",
    "\n",
    "# Loop through wave prefixes\n",
    "for prefix in wave_prefixes:\n",
    "    wave_data = load_wave_data(prefix, base_dir, base_variables)\n",
    "    if wave_data is not None:\n",
    "        all_waves_data.append(wave_data)\n",
    "\n",
    "# Combine all waves into a single DataFrame\n",
    "if all_waves_data:\n",
    "    combined_data = pd.concat(all_waves_data, ignore_index=True)\n",
    "\n",
    "    # Load the death information from xhhrel.dta\n",
    "    death_file_path = os.path.join(base_dir, 'xhhrel.dta')\n",
    "    death_data = pd.read_stata(death_file_path, convert_categoricals=False)\n",
    "\n",
    "    # Select the pidp and death column\n",
    "    death_data = death_data[['pidp', 'dcsedfl_dv']]\n",
    "\n",
    "    # Merge the death information with the combined data\n",
    "    combined_data = combined_data.merge(death_data, on='pidp', how='left')\n",
    "\n",
    "    # List of columns to clean (excluding 'pidp', 'wave', 'dcsedfl_dv', and age columns)\n",
    "    age_columns = [f'{prefix}_age_dv' for prefix in wave_prefixes]\n",
    "    columns_to_clean = [col for col in combined_data.columns if col not in ['pidp', 'wave', 'dcsedfl_dv'] + age_columns]\n",
    "\n",
    "    # Clean the data: treat everything that's not a 1 as 0\n",
    "    def clean_data(df, columns):\n",
    "        df_cleaned = df.copy()\n",
    "        for col in columns:\n",
    "            df_cleaned[col] = df_cleaned[col].apply(lambda x: 1 if x == 1 else 0)\n",
    "        return df_cleaned\n",
    "\n",
    "    # Apply the cleaning function\n",
    "    cleaned_combined_data = clean_data(combined_data, columns_to_clean)\n",
    "\n",
    "    # Create hcondever variables\n",
    "    for i in range(1, 18):\n",
    "        ever_var = f'hcondever{i}'\n",
    "        cond_cols = [f'{prefix}_hcond{i}' for prefix in wave_prefixes] + [f'hcondn{i}', f'hcondnew{i}']\n",
    "        cleaned_combined_data[ever_var] = cleaned_combined_data[cond_cols].max(axis=1)\n",
    "\n",
    "    cleaned_combined_data['hcondever21'] = cleaned_combined_data[[f'{prefix}_hcond21' for prefix in wave_prefixes]].max(axis=1)\n",
    "    cleaned_combined_data['hcondever22'] = cleaned_combined_data[[f'{prefix}_hcond22' for prefix in wave_prefixes]].max(axis=1)\n",
    "\n",
    "    # Calculate the frailty index for each wave based on hcondever variables\n",
    "    for prefix in wave_prefixes:\n",
    "        relevant_columns = [f'hcondever{i}' for i in range(1, 18)] + ['hcondever21', 'hcondever22'] + [f'{prefix}_disdif{i}' for i in range(1, 12)]\n",
    "        frailty_col = f'{prefix}_frailty'\n",
    "        cleaned_combined_data[frailty_col] = cleaned_combined_data[relevant_columns].sum(axis=1) / len(relevant_columns)\n",
    "\n",
    "    # Update age for subsequent waves\n",
    "    for i, prefix in enumerate(wave_prefixes[1:], start=1):\n",
    "        cleaned_combined_data[f'{prefix}_age_dv'] = cleaned_combined_data[f'a_age_dv'] + i\n",
    "\n",
    "    # Display the first few rows of the cleaned combined data\n",
    "    print(\"Cleaned Combined Data Head:\")\n",
    "    print(cleaned_combined_data.head())\n",
    "\n",
    "    # Save the cleaned combined data to a new Stata file\n",
    "    output_dir = '/Users/gavinqu/Desktop/School/Dissertation/EssexDissertation/Data'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cleaned_combined_data_path = os.path.join(output_dir, 'cleaned_combined_ukhls_hcond_disdif_death_data.dta')\n",
    "    cleaned_combined_data.to_stata(cleaned_combined_data_path, write_index=False)\n",
    "\n",
    "    print(f\"Cleaned combined data saved to {cleaned_combined_data_path}\")\n",
    "else:\n",
    "    print(\"No data was loaded. Please check the file paths and variable names.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
